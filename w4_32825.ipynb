{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_sdk import Studio, Teamspace, User, Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brain_score_helper\n",
    "from brain_score_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from matplotlib) (11.1.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m126.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.1 pyparsing-3.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: brainscore_vision in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (2.2.9)\n",
      "Requirement already satisfied: numpy<2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (1.26.4)\n",
      "Requirement already satisfied: brainscore-core in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (2.1.2)\n",
      "Requirement already satisfied: result-caching in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (0.1.0)\n",
      "Requirement already satisfied: importlib-metadata<5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (4.13.0)\n",
      "Requirement already satisfied: scikit-learn in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (1.15.2)\n",
      "Requirement already satisfied: opencv-python in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (4.11.0.86)\n",
      "Requirement already satisfied: h5py in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (3.13.0)\n",
      "Requirement already satisfied: tqdm in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (4.67.1)\n",
      "Requirement already satisfied: gitpython in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (3.1.44)\n",
      "Requirement already satisfied: fire in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (0.7.0)\n",
      "Requirement already satisfied: jupyter in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (1.1.1)\n",
      "Requirement already satisfied: pybtex in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (0.24.0)\n",
      "Requirement already satisfied: peewee in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (3.17.9)\n",
      "Requirement already satisfied: psycopg2-binary in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (2.9.10)\n",
      "Requirement already satisfied: networkx in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (3.4.2)\n",
      "Requirement already satisfied: eva-decord in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (0.6.1)\n",
      "Requirement already satisfied: psutil in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore_vision) (7.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from importlib-metadata<5->brainscore_vision) (3.21.0)\n",
      "Requirement already satisfied: brainscore-brainio in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore-core->brainscore_vision) (1.1.0)\n",
      "Requirement already satisfied: requests in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore-core->brainscore_vision) (2.32.3)\n",
      "Requirement already satisfied: termcolor in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from fire->brainscore_vision) (2.5.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from gitpython->brainscore_vision) (4.0.12)\n",
      "Requirement already satisfied: notebook in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter->brainscore_vision) (7.3.3)\n",
      "Requirement already satisfied: jupyter-console in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter->brainscore_vision) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter->brainscore_vision) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter->brainscore_vision) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter->brainscore_vision) (8.1.5)\n",
      "Requirement already satisfied: jupyterlab in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter->brainscore_vision) (4.3.6)\n",
      "Requirement already satisfied: PyYAML>=3.01 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from pybtex->brainscore_vision) (6.0.2)\n",
      "Requirement already satisfied: latexcodec>=1.0.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from pybtex->brainscore_vision) (3.0.0)\n",
      "Requirement already satisfied: six in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from pybtex->brainscore_vision) (1.17.0)\n",
      "Requirement already satisfied: xarray in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from result-caching->brainscore_vision) (2022.3.0)\n",
      "Requirement already satisfied: dask[array] in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from result-caching->brainscore_vision) (2025.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from scikit-learn->brainscore_vision) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from scikit-learn->brainscore_vision) (3.6.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython->brainscore_vision) (5.0.2)\n",
      "Requirement already satisfied: boto3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore-brainio->brainscore-core->brainscore_vision) (1.37.23)\n",
      "Requirement already satisfied: Pillow in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore-brainio->brainscore-core->brainscore_vision) (11.1.0)\n",
      "Requirement already satisfied: entrypoints in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore-brainio->brainscore-core->brainscore_vision) (0.4)\n",
      "Requirement already satisfied: pandas in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore-brainio->brainscore-core->brainscore_vision) (2.2.3)\n",
      "Requirement already satisfied: netcdf4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from brainscore-brainio->brainscore-core->brainscore_vision) (1.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from xarray->result-caching->brainscore_vision) (24.2)\n",
      "Requirement already satisfied: click>=8.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from dask[array]->result-caching->brainscore_vision) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from dask[array]->result-caching->brainscore_vision) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from dask[array]->result-caching->brainscore_vision) (2025.3.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from dask[array]->result-caching->brainscore_vision) (1.4.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from dask[array]->result-caching->brainscore_vision) (1.0.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipykernel->jupyter->brainscore_vision) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipykernel->jupyter->brainscore_vision) (1.8.13)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipykernel->jupyter->brainscore_vision) (9.0.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipykernel->jupyter->brainscore_vision) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipykernel->jupyter->brainscore_vision) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipykernel->jupyter->brainscore_vision) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipykernel->jupyter->brainscore_vision) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipykernel->jupyter->brainscore_vision) (26.3.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipykernel->jupyter->brainscore_vision) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipykernel->jupyter->brainscore_vision) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipywidgets->jupyter->brainscore_vision) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipywidgets->jupyter->brainscore_vision) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-console->jupyter->brainscore_vision) (3.0.50)\n",
      "Requirement already satisfied: pygments in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-console->jupyter->brainscore_vision) (2.19.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyterlab->jupyter->brainscore_vision) (2.0.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyterlab->jupyter->brainscore_vision) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyterlab->jupyter->brainscore_vision) (3.1.6)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyterlab->jupyter->brainscore_vision) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyterlab->jupyter->brainscore_vision) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyterlab->jupyter->brainscore_vision) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyterlab->jupyter->brainscore_vision) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyterlab->jupyter->brainscore_vision) (75.8.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from nbconvert->jupyter->brainscore_vision) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->brainscore_vision) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from nbconvert->jupyter->brainscore_vision) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from nbconvert->jupyter->brainscore_vision) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from nbconvert->jupyter->brainscore_vision) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from nbconvert->jupyter->brainscore_vision) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from nbconvert->jupyter->brainscore_vision) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from nbconvert->jupyter->brainscore_vision) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from nbconvert->jupyter->brainscore_vision) (1.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from requests->brainscore-core->brainscore_vision) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from requests->brainscore-core->brainscore_vision) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from requests->brainscore-core->brainscore_vision) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from requests->brainscore-core->brainscore_vision) (2025.1.31)\n",
      "Requirement already satisfied: webencodings in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->brainscore_vision) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->brainscore_vision) (1.4.0)\n",
      "Requirement already satisfied: anyio in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->jupyter->brainscore_vision) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->jupyter->brainscore_vision) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter->brainscore_vision) (0.14.0)\n",
      "Requirement already satisfied: decorator in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->brainscore_vision) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->brainscore_vision) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->brainscore_vision) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->brainscore_vision) (4.9.0)\n",
      "Requirement already satisfied: stack_data in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->brainscore_vision) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter->brainscore_vision) (4.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->brainscore_vision) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->brainscore_vision) (4.3.7)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (0.21.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->brainscore_vision) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->brainscore_vision) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->brainscore_vision) (4.23.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter->brainscore_vision) (2.21.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from pandas->brainscore-brainio->brainscore-core->brainscore_vision) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from pandas->brainscore-brainio->brainscore-core->brainscore_vision) (2025.2)\n",
      "Requirement already satisfied: locket in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from partd>=1.4.0->dask[array]->result-caching->brainscore_vision) (1.0.0)\n",
      "Requirement already satisfied: wcwidth in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->brainscore_vision) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter->brainscore_vision) (2.6)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.23 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from boto3->brainscore-brainio->brainscore-core->brainscore_vision) (1.37.23)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from boto3->brainscore-brainio->brainscore-core->brainscore_vision) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from boto3->brainscore-brainio->brainscore-core->brainscore_vision) (0.11.4)\n",
      "Requirement already satisfied: cftime in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from netcdf4->brainscore-brainio->brainscore-core->brainscore_vision) (1.6.4.post1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter->brainscore_vision) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (21.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->brainscore_vision) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->brainscore_vision) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->brainscore_vision) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->brainscore_vision) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->brainscore_vision) (0.24.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (0.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter->brainscore_vision) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->brainscore_vision) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->brainscore_vision) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->brainscore_vision) (0.2.3)\n",
      "Requirement already satisfied: fqdn in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->brainscore_vision) (2.9.0.20241206)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install brainscore_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/harvard-visionlab/neuroai-kit.git\n",
      "  Cloning https://github.com/harvard-visionlab/neuroai-kit.git to /tmp/pip-req-build-vulnzdp6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/harvard-visionlab/neuroai-kit.git /tmp/pip-req-build-vulnzdp6\n",
      "\n",
      "  Resolved https://github.com/harvard-visionlab/neuroai-kit.git to commit bbd16274b08ee9cb05aec57da034c7b49a6c635e\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: neuroai_kit\n",
      "  Building wheel for neuroai_kit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for neuroai_kit: filename=neuroai_kit-0.1.2-py3-none-any.whl size=10848 sha256=dea1a8ff12859da5bded141df1641e8127854a3fe7d4b30f9e3c5a4c4a8acb89\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qlquc292/wheels/89/36/c6/dc6948d52137f2453f5028b30a43ac66a4d2256c8aa3079305\n",
      "Successfully built neuroai_kit\n",
      "Installing collected packages: neuroai_kit\n",
      "Successfully installed neuroai_kit-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/harvard-visionlab/neuroai-kit.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainscore_vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from brainscore_vision import load_model, load_stimulus_set\n",
    "from brainscore_vision.model_interface import BrainModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let see if we can load the top 3 models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from -r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: torchvision in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from -r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: timm in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from -r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 3)) (1.0.15)\n",
      "Requirement already satisfied: filelock in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (4.13.0)\n",
      "Requirement already satisfied: networkx in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from sympy==1.13.1->torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torchvision->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torchvision->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 2)) (11.1.0)\n",
      "Requirement already satisfied: pyyaml in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from timm->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from timm->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 3)) (0.30.1)\n",
      "Requirement already satisfied: safetensors in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from timm->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 3)) (0.5.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from huggingface_hub->timm->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: requests in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from huggingface_hub->timm->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from huggingface_hub->timm->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jinja2->torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from requests->huggingface_hub->timm->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from requests->huggingface_hub->timm->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from requests->huggingface_hub->timm->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from requests->huggingface_hub->timm->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/timm_models/requirements.txt (line 3)) (2025.1.31)\n",
      "Model convnext_large_mlp loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brainscore_vision.model_helpers.brain_transformation.ModelCommitment at 0x7f2c8590b450>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Model 1: convnext_large'''\n",
    "#from brainscore_vision import load_model\n",
    "convnext_large = load_model(\"convnext_large_mlp:clip_laion2b_augreg_ft_in1k_384\")\n",
    "convnext_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 224, 224]), torch.Size([5, 1000]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "model = convnext_large.activations_model._model\n",
    "x = torch.randn(5,3,224,224)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "x.shape, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timm.models.convnext.ConvNeXt"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': (3, 384, 384),\n",
       " 'interpolation': 'bicubic',\n",
       " 'mean': (0.48145466, 0.4578275, 0.40821073),\n",
       " 'std': (0.26862954, 0.26130258, 0.27577711),\n",
       " 'crop_pct': 1.0,\n",
       " 'crop_mode': 'squash'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm \n",
    "timm.__version__\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from -r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: torchvision in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from -r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: filelock in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (4.13.0)\n",
      "Requirement already satisfied: networkx in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from sympy==1.13.1->torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torchvision->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from torchvision->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 2)) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages (from jinja2->torch->-r /home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/brainscore_vision/models/alexnet/requirements.txt (line 1)) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /home/zeus/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
      "100%|██████████| 233M/233M [00:04<00:00, 55.1MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brainscore_vision.model_helpers.brain_transformation.ModelCommitment at 0x7f2cb5f331d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brainscore_model = load_model(\"alexnet\")\n",
    "convnext_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brainscore_model.activations_model.image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RecordingTarget', 'Task', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_logger', '_visual_degrees', 'activations_model', 'behavior_model', 'do_behavior', 'identifier', 'layer_model', 'layers', 'load_region_layer_map_json', 'look_at', 'start_recording', 'start_task', 'visual_degrees']\n"
     ]
    }
   ],
   "source": [
    "print(dir(convnext_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'brainscore_vision.model_helpers.activations.pytorch.PytorchWrapper'>\n",
      "['__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_build_extractor', '_device', '_extractor', '_forward_kwargs', '_model', '_output_layer', '_tensor_to_numpy', 'from_paths', 'from_stimulus_set', 'get_activations', 'get_layer', 'graph', 'identifier', 'layers', 'register_batch_activations_hook', 'register_hook', 'register_stimulus_set_hook']\n"
     ]
    }
   ],
   "source": [
    "print(type(convnext_large.activations_model))\n",
    "print(dir(convnext_large.activations_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PytorchWrapper' object has no attribute '_sizeof_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mconvnext_large\u001b[49m\u001b[43m.\u001b[49m\u001b[43mactivations_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_sizeof_\u001b[49m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'PytorchWrapper' object has no attribute '_sizeof_'"
     ]
    }
   ],
   "source": [
    "print(convnext_large.activations_model._sizeof_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can i find original model\n",
    "# print(convnext_large.activations_model._model)\n",
    "underlying_model = convnext_large.activations_model._model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXt(\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (1): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (stages): Sequential(\n",
      "    (0): ConvNeXtStage(\n",
      "      (downsample): Identity()\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ConvNeXtStage(\n",
      "      (downsample): Sequential(\n",
      "        (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): ConvNeXtStage(\n",
      "      (downsample): Sequential(\n",
      "        (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (4): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (5): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (6): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (7): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (8): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (9): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (10): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (11): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (12): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (13): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (14): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (15): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (16): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (17): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (18): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (19): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (20): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (21): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (22): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (23): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (24): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (25): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (26): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): ConvNeXtStage(\n",
      "      (downsample): Sequential(\n",
      "        (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(768, 1536, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
      "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
      "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
      "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm_pre): Identity()\n",
      "  (head): NormMlpClassifierHead(\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "    (norm): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (pre_logits): Sequential(\n",
      "      (fc): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (act): GELU()\n",
      "    )\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# print(convnext_large.activations_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'blocks'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      5\u001b[39m layers = {\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mstem\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mstem\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mstages\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mstages.0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstages.1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstages.2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstages.3\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhead\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mhead\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     15\u001b[39m }\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Using NeuroElectrodeArray directly:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNeuroElectrodeArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43munderlying_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melectrode\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43melectrode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/neuroai_kit/electrode.py:59\u001b[39m, in \u001b[36mNeuroElectrodeArray.__enter__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args): \n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhook_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/neuroai_kit/electrode.py:47\u001b[39m, in \u001b[36mNeuroElectrodeArray.hook_layers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mself\u001b[39m.remove_hooks()\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     layer = \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnamed_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mself\u001b[39m.hooks[layer_id] = layer.register_forward_hook(\u001b[38;5;28mself\u001b[39m.save_outputs_hook(layer_id))\n",
      "\u001b[31mKeyError\u001b[39m: 'blocks'"
     ]
    }
   ],
   "source": [
    "# import neuroai_kit as nk\n",
    "# from neuroai_kit import model_utils\n",
    "# from neuroai_kit.electrode import NeuroElectrodeArray\n",
    "\n",
    "# layers = {\n",
    "#     'stem': 'stem',\n",
    "#     'stages': ['stages.0', 'stages.1', 'stages.2', 'stages.3'],\n",
    "#     'blocks': {\n",
    "#         'stages.0': [f'stages.0.blocks.{i}' for i in range(3)],\n",
    "#         'stages.1': [f'stages.1.blocks.{i}' for i in range(3)],\n",
    "#         'stages.2': [f'stages.2.blocks.{i}' for i in range(27)],\n",
    "#         'stages.3': [f'stages.3.blocks.{i}' for i in range(3)]\n",
    "#     },\n",
    "#     'head': 'head'\n",
    "# }\n",
    "\n",
    "# # Using NeuroElectrodeArray directly:\n",
    "# with NeuroElectrodeArray(underlying_model, layers=layers) as electrode:\n",
    "#     activations = electrode(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total layers found: 466\n",
      "0: stem\n",
      "1: stem.0\n",
      "2: stem.1\n",
      "3: stages\n",
      "4: stages.0\n",
      "5: stages.0.downsample\n",
      "6: stages.0.blocks\n",
      "7: stages.0.blocks.0\n",
      "8: stages.0.blocks.0.conv_dw\n",
      "9: stages.0.blocks.0.norm\n",
      "10: stages.0.blocks.0.mlp\n",
      "11: stages.0.blocks.0.mlp.fc1\n",
      "12: stages.0.blocks.0.mlp.act\n",
      "13: stages.0.blocks.0.mlp.drop1\n",
      "14: stages.0.blocks.0.mlp.norm\n",
      "15: stages.0.blocks.0.mlp.fc2\n",
      "16: stages.0.blocks.0.mlp.drop2\n",
      "17: stages.0.blocks.0.shortcut\n",
      "18: stages.0.blocks.0.drop_path\n",
      "19: stages.0.blocks.1\n",
      "20: stages.0.blocks.1.conv_dw\n",
      "21: stages.0.blocks.1.norm\n",
      "22: stages.0.blocks.1.mlp\n",
      "23: stages.0.blocks.1.mlp.fc1\n",
      "24: stages.0.blocks.1.mlp.act\n",
      "25: stages.0.blocks.1.mlp.drop1\n",
      "26: stages.0.blocks.1.mlp.norm\n",
      "27: stages.0.blocks.1.mlp.fc2\n",
      "28: stages.0.blocks.1.mlp.drop2\n",
      "29: stages.0.blocks.1.shortcut\n",
      "30: stages.0.blocks.1.drop_path\n",
      "31: stages.0.blocks.2\n",
      "32: stages.0.blocks.2.conv_dw\n",
      "33: stages.0.blocks.2.norm\n",
      "34: stages.0.blocks.2.mlp\n",
      "35: stages.0.blocks.2.mlp.fc1\n",
      "36: stages.0.blocks.2.mlp.act\n",
      "37: stages.0.blocks.2.mlp.drop1\n",
      "38: stages.0.blocks.2.mlp.norm\n",
      "39: stages.0.blocks.2.mlp.fc2\n",
      "40: stages.0.blocks.2.mlp.drop2\n",
      "41: stages.0.blocks.2.shortcut\n",
      "42: stages.0.blocks.2.drop_path\n",
      "43: stages.1\n",
      "44: stages.1.downsample\n",
      "45: stages.1.downsample.0\n",
      "46: stages.1.downsample.1\n",
      "47: stages.1.blocks\n",
      "48: stages.1.blocks.0\n",
      "49: stages.1.blocks.0.conv_dw\n",
      "50: stages.1.blocks.0.norm\n",
      "51: stages.1.blocks.0.mlp\n",
      "52: stages.1.blocks.0.mlp.fc1\n",
      "53: stages.1.blocks.0.mlp.act\n",
      "54: stages.1.blocks.0.mlp.drop1\n",
      "55: stages.1.blocks.0.mlp.norm\n",
      "56: stages.1.blocks.0.mlp.fc2\n",
      "57: stages.1.blocks.0.mlp.drop2\n",
      "58: stages.1.blocks.0.shortcut\n",
      "59: stages.1.blocks.0.drop_path\n",
      "60: stages.1.blocks.1\n",
      "61: stages.1.blocks.1.conv_dw\n",
      "62: stages.1.blocks.1.norm\n",
      "63: stages.1.blocks.1.mlp\n",
      "64: stages.1.blocks.1.mlp.fc1\n",
      "65: stages.1.blocks.1.mlp.act\n",
      "66: stages.1.blocks.1.mlp.drop1\n",
      "67: stages.1.blocks.1.mlp.norm\n",
      "68: stages.1.blocks.1.mlp.fc2\n",
      "69: stages.1.blocks.1.mlp.drop2\n",
      "70: stages.1.blocks.1.shortcut\n",
      "71: stages.1.blocks.1.drop_path\n",
      "72: stages.1.blocks.2\n",
      "73: stages.1.blocks.2.conv_dw\n",
      "74: stages.1.blocks.2.norm\n",
      "75: stages.1.blocks.2.mlp\n",
      "76: stages.1.blocks.2.mlp.fc1\n",
      "77: stages.1.blocks.2.mlp.act\n",
      "78: stages.1.blocks.2.mlp.drop1\n",
      "79: stages.1.blocks.2.mlp.norm\n",
      "80: stages.1.blocks.2.mlp.fc2\n",
      "81: stages.1.blocks.2.mlp.drop2\n",
      "82: stages.1.blocks.2.shortcut\n",
      "83: stages.1.blocks.2.drop_path\n",
      "84: stages.2\n",
      "85: stages.2.downsample\n",
      "86: stages.2.downsample.0\n",
      "87: stages.2.downsample.1\n",
      "88: stages.2.blocks\n",
      "89: stages.2.blocks.0\n",
      "90: stages.2.blocks.0.conv_dw\n",
      "91: stages.2.blocks.0.norm\n",
      "92: stages.2.blocks.0.mlp\n",
      "93: stages.2.blocks.0.mlp.fc1\n",
      "94: stages.2.blocks.0.mlp.act\n",
      "95: stages.2.blocks.0.mlp.drop1\n",
      "96: stages.2.blocks.0.mlp.norm\n",
      "97: stages.2.blocks.0.mlp.fc2\n",
      "98: stages.2.blocks.0.mlp.drop2\n",
      "99: stages.2.blocks.0.shortcut\n",
      "100: stages.2.blocks.0.drop_path\n",
      "101: stages.2.blocks.1\n",
      "102: stages.2.blocks.1.conv_dw\n",
      "103: stages.2.blocks.1.norm\n",
      "104: stages.2.blocks.1.mlp\n",
      "105: stages.2.blocks.1.mlp.fc1\n",
      "106: stages.2.blocks.1.mlp.act\n",
      "107: stages.2.blocks.1.mlp.drop1\n",
      "108: stages.2.blocks.1.mlp.norm\n",
      "109: stages.2.blocks.1.mlp.fc2\n",
      "110: stages.2.blocks.1.mlp.drop2\n",
      "111: stages.2.blocks.1.shortcut\n",
      "112: stages.2.blocks.1.drop_path\n",
      "113: stages.2.blocks.2\n",
      "114: stages.2.blocks.2.conv_dw\n",
      "115: stages.2.blocks.2.norm\n",
      "116: stages.2.blocks.2.mlp\n",
      "117: stages.2.blocks.2.mlp.fc1\n",
      "118: stages.2.blocks.2.mlp.act\n",
      "119: stages.2.blocks.2.mlp.drop1\n",
      "120: stages.2.blocks.2.mlp.norm\n",
      "121: stages.2.blocks.2.mlp.fc2\n",
      "122: stages.2.blocks.2.mlp.drop2\n",
      "123: stages.2.blocks.2.shortcut\n",
      "124: stages.2.blocks.2.drop_path\n",
      "125: stages.2.blocks.3\n",
      "126: stages.2.blocks.3.conv_dw\n",
      "127: stages.2.blocks.3.norm\n",
      "128: stages.2.blocks.3.mlp\n",
      "129: stages.2.blocks.3.mlp.fc1\n",
      "130: stages.2.blocks.3.mlp.act\n",
      "131: stages.2.blocks.3.mlp.drop1\n",
      "132: stages.2.blocks.3.mlp.norm\n",
      "133: stages.2.blocks.3.mlp.fc2\n",
      "134: stages.2.blocks.3.mlp.drop2\n",
      "135: stages.2.blocks.3.shortcut\n",
      "136: stages.2.blocks.3.drop_path\n",
      "137: stages.2.blocks.4\n",
      "138: stages.2.blocks.4.conv_dw\n",
      "139: stages.2.blocks.4.norm\n",
      "140: stages.2.blocks.4.mlp\n",
      "141: stages.2.blocks.4.mlp.fc1\n",
      "142: stages.2.blocks.4.mlp.act\n",
      "143: stages.2.blocks.4.mlp.drop1\n",
      "144: stages.2.blocks.4.mlp.norm\n",
      "145: stages.2.blocks.4.mlp.fc2\n",
      "146: stages.2.blocks.4.mlp.drop2\n",
      "147: stages.2.blocks.4.shortcut\n",
      "148: stages.2.blocks.4.drop_path\n",
      "149: stages.2.blocks.5\n",
      "150: stages.2.blocks.5.conv_dw\n",
      "151: stages.2.blocks.5.norm\n",
      "152: stages.2.blocks.5.mlp\n",
      "153: stages.2.blocks.5.mlp.fc1\n",
      "154: stages.2.blocks.5.mlp.act\n",
      "155: stages.2.blocks.5.mlp.drop1\n",
      "156: stages.2.blocks.5.mlp.norm\n",
      "157: stages.2.blocks.5.mlp.fc2\n",
      "158: stages.2.blocks.5.mlp.drop2\n",
      "159: stages.2.blocks.5.shortcut\n",
      "160: stages.2.blocks.5.drop_path\n",
      "161: stages.2.blocks.6\n",
      "162: stages.2.blocks.6.conv_dw\n",
      "163: stages.2.blocks.6.norm\n",
      "164: stages.2.blocks.6.mlp\n",
      "165: stages.2.blocks.6.mlp.fc1\n",
      "166: stages.2.blocks.6.mlp.act\n",
      "167: stages.2.blocks.6.mlp.drop1\n",
      "168: stages.2.blocks.6.mlp.norm\n",
      "169: stages.2.blocks.6.mlp.fc2\n",
      "170: stages.2.blocks.6.mlp.drop2\n",
      "171: stages.2.blocks.6.shortcut\n",
      "172: stages.2.blocks.6.drop_path\n",
      "173: stages.2.blocks.7\n",
      "174: stages.2.blocks.7.conv_dw\n",
      "175: stages.2.blocks.7.norm\n",
      "176: stages.2.blocks.7.mlp\n",
      "177: stages.2.blocks.7.mlp.fc1\n",
      "178: stages.2.blocks.7.mlp.act\n",
      "179: stages.2.blocks.7.mlp.drop1\n",
      "180: stages.2.blocks.7.mlp.norm\n",
      "181: stages.2.blocks.7.mlp.fc2\n",
      "182: stages.2.blocks.7.mlp.drop2\n",
      "183: stages.2.blocks.7.shortcut\n",
      "184: stages.2.blocks.7.drop_path\n",
      "185: stages.2.blocks.8\n",
      "186: stages.2.blocks.8.conv_dw\n",
      "187: stages.2.blocks.8.norm\n",
      "188: stages.2.blocks.8.mlp\n",
      "189: stages.2.blocks.8.mlp.fc1\n",
      "190: stages.2.blocks.8.mlp.act\n",
      "191: stages.2.blocks.8.mlp.drop1\n",
      "192: stages.2.blocks.8.mlp.norm\n",
      "193: stages.2.blocks.8.mlp.fc2\n",
      "194: stages.2.blocks.8.mlp.drop2\n",
      "195: stages.2.blocks.8.shortcut\n",
      "196: stages.2.blocks.8.drop_path\n",
      "197: stages.2.blocks.9\n",
      "198: stages.2.blocks.9.conv_dw\n",
      "199: stages.2.blocks.9.norm\n",
      "200: stages.2.blocks.9.mlp\n",
      "201: stages.2.blocks.9.mlp.fc1\n",
      "202: stages.2.blocks.9.mlp.act\n",
      "203: stages.2.blocks.9.mlp.drop1\n",
      "204: stages.2.blocks.9.mlp.norm\n",
      "205: stages.2.blocks.9.mlp.fc2\n",
      "206: stages.2.blocks.9.mlp.drop2\n",
      "207: stages.2.blocks.9.shortcut\n",
      "208: stages.2.blocks.9.drop_path\n",
      "209: stages.2.blocks.10\n",
      "210: stages.2.blocks.10.conv_dw\n",
      "211: stages.2.blocks.10.norm\n",
      "212: stages.2.blocks.10.mlp\n",
      "213: stages.2.blocks.10.mlp.fc1\n",
      "214: stages.2.blocks.10.mlp.act\n",
      "215: stages.2.blocks.10.mlp.drop1\n",
      "216: stages.2.blocks.10.mlp.norm\n",
      "217: stages.2.blocks.10.mlp.fc2\n",
      "218: stages.2.blocks.10.mlp.drop2\n",
      "219: stages.2.blocks.10.shortcut\n",
      "220: stages.2.blocks.10.drop_path\n",
      "221: stages.2.blocks.11\n",
      "222: stages.2.blocks.11.conv_dw\n",
      "223: stages.2.blocks.11.norm\n",
      "224: stages.2.blocks.11.mlp\n",
      "225: stages.2.blocks.11.mlp.fc1\n",
      "226: stages.2.blocks.11.mlp.act\n",
      "227: stages.2.blocks.11.mlp.drop1\n",
      "228: stages.2.blocks.11.mlp.norm\n",
      "229: stages.2.blocks.11.mlp.fc2\n",
      "230: stages.2.blocks.11.mlp.drop2\n",
      "231: stages.2.blocks.11.shortcut\n",
      "232: stages.2.blocks.11.drop_path\n",
      "233: stages.2.blocks.12\n",
      "234: stages.2.blocks.12.conv_dw\n",
      "235: stages.2.blocks.12.norm\n",
      "236: stages.2.blocks.12.mlp\n",
      "237: stages.2.blocks.12.mlp.fc1\n",
      "238: stages.2.blocks.12.mlp.act\n",
      "239: stages.2.blocks.12.mlp.drop1\n",
      "240: stages.2.blocks.12.mlp.norm\n",
      "241: stages.2.blocks.12.mlp.fc2\n",
      "242: stages.2.blocks.12.mlp.drop2\n",
      "243: stages.2.blocks.12.shortcut\n",
      "244: stages.2.blocks.12.drop_path\n",
      "245: stages.2.blocks.13\n",
      "246: stages.2.blocks.13.conv_dw\n",
      "247: stages.2.blocks.13.norm\n",
      "248: stages.2.blocks.13.mlp\n",
      "249: stages.2.blocks.13.mlp.fc1\n",
      "250: stages.2.blocks.13.mlp.act\n",
      "251: stages.2.blocks.13.mlp.drop1\n",
      "252: stages.2.blocks.13.mlp.norm\n",
      "253: stages.2.blocks.13.mlp.fc2\n",
      "254: stages.2.blocks.13.mlp.drop2\n",
      "255: stages.2.blocks.13.shortcut\n",
      "256: stages.2.blocks.13.drop_path\n",
      "257: stages.2.blocks.14\n",
      "258: stages.2.blocks.14.conv_dw\n",
      "259: stages.2.blocks.14.norm\n",
      "260: stages.2.blocks.14.mlp\n",
      "261: stages.2.blocks.14.mlp.fc1\n",
      "262: stages.2.blocks.14.mlp.act\n",
      "263: stages.2.blocks.14.mlp.drop1\n",
      "264: stages.2.blocks.14.mlp.norm\n",
      "265: stages.2.blocks.14.mlp.fc2\n",
      "266: stages.2.blocks.14.mlp.drop2\n",
      "267: stages.2.blocks.14.shortcut\n",
      "268: stages.2.blocks.14.drop_path\n",
      "269: stages.2.blocks.15\n",
      "270: stages.2.blocks.15.conv_dw\n",
      "271: stages.2.blocks.15.norm\n",
      "272: stages.2.blocks.15.mlp\n",
      "273: stages.2.blocks.15.mlp.fc1\n",
      "274: stages.2.blocks.15.mlp.act\n",
      "275: stages.2.blocks.15.mlp.drop1\n",
      "276: stages.2.blocks.15.mlp.norm\n",
      "277: stages.2.blocks.15.mlp.fc2\n",
      "278: stages.2.blocks.15.mlp.drop2\n",
      "279: stages.2.blocks.15.shortcut\n",
      "280: stages.2.blocks.15.drop_path\n",
      "281: stages.2.blocks.16\n",
      "282: stages.2.blocks.16.conv_dw\n",
      "283: stages.2.blocks.16.norm\n",
      "284: stages.2.blocks.16.mlp\n",
      "285: stages.2.blocks.16.mlp.fc1\n",
      "286: stages.2.blocks.16.mlp.act\n",
      "287: stages.2.blocks.16.mlp.drop1\n",
      "288: stages.2.blocks.16.mlp.norm\n",
      "289: stages.2.blocks.16.mlp.fc2\n",
      "290: stages.2.blocks.16.mlp.drop2\n",
      "291: stages.2.blocks.16.shortcut\n",
      "292: stages.2.blocks.16.drop_path\n",
      "293: stages.2.blocks.17\n",
      "294: stages.2.blocks.17.conv_dw\n",
      "295: stages.2.blocks.17.norm\n",
      "296: stages.2.blocks.17.mlp\n",
      "297: stages.2.blocks.17.mlp.fc1\n",
      "298: stages.2.blocks.17.mlp.act\n",
      "299: stages.2.blocks.17.mlp.drop1\n",
      "300: stages.2.blocks.17.mlp.norm\n",
      "301: stages.2.blocks.17.mlp.fc2\n",
      "302: stages.2.blocks.17.mlp.drop2\n",
      "303: stages.2.blocks.17.shortcut\n",
      "304: stages.2.blocks.17.drop_path\n",
      "305: stages.2.blocks.18\n",
      "306: stages.2.blocks.18.conv_dw\n",
      "307: stages.2.blocks.18.norm\n",
      "308: stages.2.blocks.18.mlp\n",
      "309: stages.2.blocks.18.mlp.fc1\n",
      "310: stages.2.blocks.18.mlp.act\n",
      "311: stages.2.blocks.18.mlp.drop1\n",
      "312: stages.2.blocks.18.mlp.norm\n",
      "313: stages.2.blocks.18.mlp.fc2\n",
      "314: stages.2.blocks.18.mlp.drop2\n",
      "315: stages.2.blocks.18.shortcut\n",
      "316: stages.2.blocks.18.drop_path\n",
      "317: stages.2.blocks.19\n",
      "318: stages.2.blocks.19.conv_dw\n",
      "319: stages.2.blocks.19.norm\n",
      "320: stages.2.blocks.19.mlp\n",
      "321: stages.2.blocks.19.mlp.fc1\n",
      "322: stages.2.blocks.19.mlp.act\n",
      "323: stages.2.blocks.19.mlp.drop1\n",
      "324: stages.2.blocks.19.mlp.norm\n",
      "325: stages.2.blocks.19.mlp.fc2\n",
      "326: stages.2.blocks.19.mlp.drop2\n",
      "327: stages.2.blocks.19.shortcut\n",
      "328: stages.2.blocks.19.drop_path\n",
      "329: stages.2.blocks.20\n",
      "330: stages.2.blocks.20.conv_dw\n",
      "331: stages.2.blocks.20.norm\n",
      "332: stages.2.blocks.20.mlp\n",
      "333: stages.2.blocks.20.mlp.fc1\n",
      "334: stages.2.blocks.20.mlp.act\n",
      "335: stages.2.blocks.20.mlp.drop1\n",
      "336: stages.2.blocks.20.mlp.norm\n",
      "337: stages.2.blocks.20.mlp.fc2\n",
      "338: stages.2.blocks.20.mlp.drop2\n",
      "339: stages.2.blocks.20.shortcut\n",
      "340: stages.2.blocks.20.drop_path\n",
      "341: stages.2.blocks.21\n",
      "342: stages.2.blocks.21.conv_dw\n",
      "343: stages.2.blocks.21.norm\n",
      "344: stages.2.blocks.21.mlp\n",
      "345: stages.2.blocks.21.mlp.fc1\n",
      "346: stages.2.blocks.21.mlp.act\n",
      "347: stages.2.blocks.21.mlp.drop1\n",
      "348: stages.2.blocks.21.mlp.norm\n",
      "349: stages.2.blocks.21.mlp.fc2\n",
      "350: stages.2.blocks.21.mlp.drop2\n",
      "351: stages.2.blocks.21.shortcut\n",
      "352: stages.2.blocks.21.drop_path\n",
      "353: stages.2.blocks.22\n",
      "354: stages.2.blocks.22.conv_dw\n",
      "355: stages.2.blocks.22.norm\n",
      "356: stages.2.blocks.22.mlp\n",
      "357: stages.2.blocks.22.mlp.fc1\n",
      "358: stages.2.blocks.22.mlp.act\n",
      "359: stages.2.blocks.22.mlp.drop1\n",
      "360: stages.2.blocks.22.mlp.norm\n",
      "361: stages.2.blocks.22.mlp.fc2\n",
      "362: stages.2.blocks.22.mlp.drop2\n",
      "363: stages.2.blocks.22.shortcut\n",
      "364: stages.2.blocks.22.drop_path\n",
      "365: stages.2.blocks.23\n",
      "366: stages.2.blocks.23.conv_dw\n",
      "367: stages.2.blocks.23.norm\n",
      "368: stages.2.blocks.23.mlp\n",
      "369: stages.2.blocks.23.mlp.fc1\n",
      "370: stages.2.blocks.23.mlp.act\n",
      "371: stages.2.blocks.23.mlp.drop1\n",
      "372: stages.2.blocks.23.mlp.norm\n",
      "373: stages.2.blocks.23.mlp.fc2\n",
      "374: stages.2.blocks.23.mlp.drop2\n",
      "375: stages.2.blocks.23.shortcut\n",
      "376: stages.2.blocks.23.drop_path\n",
      "377: stages.2.blocks.24\n",
      "378: stages.2.blocks.24.conv_dw\n",
      "379: stages.2.blocks.24.norm\n",
      "380: stages.2.blocks.24.mlp\n",
      "381: stages.2.blocks.24.mlp.fc1\n",
      "382: stages.2.blocks.24.mlp.act\n",
      "383: stages.2.blocks.24.mlp.drop1\n",
      "384: stages.2.blocks.24.mlp.norm\n",
      "385: stages.2.blocks.24.mlp.fc2\n",
      "386: stages.2.blocks.24.mlp.drop2\n",
      "387: stages.2.blocks.24.shortcut\n",
      "388: stages.2.blocks.24.drop_path\n",
      "389: stages.2.blocks.25\n",
      "390: stages.2.blocks.25.conv_dw\n",
      "391: stages.2.blocks.25.norm\n",
      "392: stages.2.blocks.25.mlp\n",
      "393: stages.2.blocks.25.mlp.fc1\n",
      "394: stages.2.blocks.25.mlp.act\n",
      "395: stages.2.blocks.25.mlp.drop1\n",
      "396: stages.2.blocks.25.mlp.norm\n",
      "397: stages.2.blocks.25.mlp.fc2\n",
      "398: stages.2.blocks.25.mlp.drop2\n",
      "399: stages.2.blocks.25.shortcut\n",
      "400: stages.2.blocks.25.drop_path\n",
      "401: stages.2.blocks.26\n",
      "402: stages.2.blocks.26.conv_dw\n",
      "403: stages.2.blocks.26.norm\n",
      "404: stages.2.blocks.26.mlp\n",
      "405: stages.2.blocks.26.mlp.fc1\n",
      "406: stages.2.blocks.26.mlp.act\n",
      "407: stages.2.blocks.26.mlp.drop1\n",
      "408: stages.2.blocks.26.mlp.norm\n",
      "409: stages.2.blocks.26.mlp.fc2\n",
      "410: stages.2.blocks.26.mlp.drop2\n",
      "411: stages.2.blocks.26.shortcut\n",
      "412: stages.2.blocks.26.drop_path\n",
      "413: stages.3\n",
      "414: stages.3.downsample\n",
      "415: stages.3.downsample.0\n",
      "416: stages.3.downsample.1\n",
      "417: stages.3.blocks\n",
      "418: stages.3.blocks.0\n",
      "419: stages.3.blocks.0.conv_dw\n",
      "420: stages.3.blocks.0.norm\n",
      "421: stages.3.blocks.0.mlp\n",
      "422: stages.3.blocks.0.mlp.fc1\n",
      "423: stages.3.blocks.0.mlp.act\n",
      "424: stages.3.blocks.0.mlp.drop1\n",
      "425: stages.3.blocks.0.mlp.norm\n",
      "426: stages.3.blocks.0.mlp.fc2\n",
      "427: stages.3.blocks.0.mlp.drop2\n",
      "428: stages.3.blocks.0.shortcut\n",
      "429: stages.3.blocks.0.drop_path\n",
      "430: stages.3.blocks.1\n",
      "431: stages.3.blocks.1.conv_dw\n",
      "432: stages.3.blocks.1.norm\n",
      "433: stages.3.blocks.1.mlp\n",
      "434: stages.3.blocks.1.mlp.fc1\n",
      "435: stages.3.blocks.1.mlp.act\n",
      "436: stages.3.blocks.1.mlp.drop1\n",
      "437: stages.3.blocks.1.mlp.norm\n",
      "438: stages.3.blocks.1.mlp.fc2\n",
      "439: stages.3.blocks.1.mlp.drop2\n",
      "440: stages.3.blocks.1.shortcut\n",
      "441: stages.3.blocks.1.drop_path\n",
      "442: stages.3.blocks.2\n",
      "443: stages.3.blocks.2.conv_dw\n",
      "444: stages.3.blocks.2.norm\n",
      "445: stages.3.blocks.2.mlp\n",
      "446: stages.3.blocks.2.mlp.fc1\n",
      "447: stages.3.blocks.2.mlp.act\n",
      "448: stages.3.blocks.2.mlp.drop1\n",
      "449: stages.3.blocks.2.mlp.norm\n",
      "450: stages.3.blocks.2.mlp.fc2\n",
      "451: stages.3.blocks.2.mlp.drop2\n",
      "452: stages.3.blocks.2.shortcut\n",
      "453: stages.3.blocks.2.drop_path\n",
      "454: norm_pre\n",
      "455: head\n",
      "456: head.global_pool\n",
      "457: head.global_pool.pool\n",
      "458: head.global_pool.flatten\n",
      "459: head.norm\n",
      "460: head.flatten\n",
      "461: head.pre_logits\n",
      "462: head.pre_logits.fc\n",
      "463: head.pre_logits.act\n",
      "464: head.drop\n",
      "465: head.fc\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from neuroai_kit.electrode import NeuroElectrodeArray\n",
    "\n",
    "# Get the underlying PyTorch model\n",
    "underlying_model = convnext_large.activations_model._model\n",
    "\n",
    "# Function to get all named modules as flattened paths\n",
    "def get_all_layers(model):\n",
    "    return [name for name, _ in model.named_modules() if name != '']  # Skip the root module\n",
    "\n",
    "# Get all layer paths\n",
    "all_layers = get_all_layers(underlying_model)\n",
    "\n",
    "# Print all available layers to inspect\n",
    "print(f\"Total layers found: {len(all_layers)}\")\n",
    "for i, layer in enumerate(all_layers):\n",
    "    print(f\"{i}: {layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: stem, Shape: torch.Size([1, 192, 56, 56])\n",
      "Layer: stages.0, Shape: torch.Size([1, 192, 56, 56])\n",
      "Layer: stages.0.blocks.0.mlp.act, Shape: torch.Size([1, 56, 56, 768])\n",
      "Layer: stages.0.blocks.0.norm, Shape: torch.Size([1, 56, 56, 192])\n",
      "Layer: stages.0.blocks.0, Shape: torch.Size([1, 192, 56, 56])\n",
      "Layer: stages.0.blocks.1.mlp.act, Shape: torch.Size([1, 56, 56, 768])\n",
      "Layer: stages.0.blocks.1.norm, Shape: torch.Size([1, 56, 56, 192])\n",
      "Layer: stages.0.blocks.1, Shape: torch.Size([1, 192, 56, 56])\n",
      "Layer: stages.0.blocks.2.mlp.act, Shape: torch.Size([1, 56, 56, 768])\n",
      "Layer: stages.0.blocks.2.norm, Shape: torch.Size([1, 56, 56, 192])\n",
      "Layer: stages.0.blocks.2, Shape: torch.Size([1, 192, 56, 56])\n",
      "Layer: stages.1, Shape: torch.Size([1, 384, 28, 28])\n",
      "Layer: stages.1.blocks.0.mlp.act, Shape: torch.Size([1, 28, 28, 1536])\n",
      "Layer: stages.1.blocks.0.norm, Shape: torch.Size([1, 28, 28, 384])\n",
      "Layer: stages.1.blocks.0, Shape: torch.Size([1, 384, 28, 28])\n",
      "Layer: stages.1.blocks.1.mlp.act, Shape: torch.Size([1, 28, 28, 1536])\n",
      "Layer: stages.1.blocks.1.norm, Shape: torch.Size([1, 28, 28, 384])\n",
      "Layer: stages.1.blocks.1, Shape: torch.Size([1, 384, 28, 28])\n",
      "Layer: stages.1.blocks.2.mlp.act, Shape: torch.Size([1, 28, 28, 1536])\n",
      "Layer: stages.1.blocks.2.norm, Shape: torch.Size([1, 28, 28, 384])\n",
      "Layer: stages.1.blocks.2, Shape: torch.Size([1, 384, 28, 28])\n",
      "Layer: stages.2, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.0.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.0.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.0, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.1.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.1.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.1, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.2.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.2.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.2, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.3.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.3.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.3, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.4.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.4.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.4, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.5.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.5.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.5, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.6.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.6.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.6, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.7.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.7.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.7, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.8.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.8.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.8, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.9.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.9.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.9, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.10.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.10.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.10, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.11.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.11.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.11, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.12.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.12.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.12, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.13.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.13.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.13, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.14.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.14.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.14, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.15.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.15.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.15, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.16.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.16.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.16, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.17.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.17.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.17, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.18.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.18.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.18, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.19.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.19.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.19, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.20.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.20.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.20, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.21.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.21.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.21, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.22.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.22.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.22, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.23.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.23.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.23, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.24.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.24.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.24, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.25.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.25.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.25, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.2.blocks.26.mlp.act, Shape: torch.Size([1, 14, 14, 3072])\n",
      "Layer: stages.2.blocks.26.norm, Shape: torch.Size([1, 14, 14, 768])\n",
      "Layer: stages.2.blocks.26, Shape: torch.Size([1, 768, 14, 14])\n",
      "Layer: stages.3, Shape: torch.Size([1, 1536, 7, 7])\n",
      "Layer: stages.3.blocks.0.mlp.act, Shape: torch.Size([1, 7, 7, 6144])\n",
      "Layer: stages.3.blocks.0.norm, Shape: torch.Size([1, 7, 7, 1536])\n",
      "Layer: stages.3.blocks.0, Shape: torch.Size([1, 1536, 7, 7])\n",
      "Layer: stages.3.blocks.1.mlp.act, Shape: torch.Size([1, 7, 7, 6144])\n",
      "Layer: stages.3.blocks.1.norm, Shape: torch.Size([1, 7, 7, 1536])\n",
      "Layer: stages.3.blocks.1, Shape: torch.Size([1, 1536, 7, 7])\n",
      "Layer: stages.3.blocks.2.mlp.act, Shape: torch.Size([1, 7, 7, 6144])\n",
      "Layer: stages.3.blocks.2.norm, Shape: torch.Size([1, 7, 7, 1536])\n",
      "Layer: stages.3.blocks.2, Shape: torch.Size([1, 1536, 7, 7])\n",
      "Layer: head, Shape: torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from neuroai_kit.electrode import NeuroElectrodeArray\n",
    "\n",
    "# Assuming convnext_large is already defined and loaded somewhere else\n",
    "# Get the underlying PyTorch model from the wrapper\n",
    "underlying_model = convnext_large.activations_model._model  # Adjust as needed\n",
    "\n",
    "# Build the flattened list of layers to extract activations from:\n",
    "layers = []\n",
    "\n",
    "# 1. Add the stem layer\n",
    "layers.append('stem')\n",
    "\n",
    "# 2. Add stages and block-level layers\n",
    "for stage_idx in range(4):  # stages 0, 1, 2, 3\n",
    "    stage_name = f\"stages.{stage_idx}\"\n",
    "    layers.append(stage_name)  # Include the whole stage if needed\n",
    "    \n",
    "    # Determine the number of blocks: stage 2 has 27 blocks, others have 3 each.\n",
    "    num_blocks = 27 if stage_idx == 2 else 3\n",
    "    for block_idx in range(num_blocks):\n",
    "        block_prefix = f\"{stage_name}.blocks.{block_idx}\"\n",
    "        # Add key activation points from each block:\n",
    "        # MLP activation, normalization, and optionally the entire block output.\n",
    "        layers.append(f\"{block_prefix}.mlp.act\")\n",
    "        layers.append(f\"{block_prefix}.norm\")\n",
    "        layers.append(block_prefix)\n",
    "\n",
    "# 3. Add the head of the model\n",
    "layers.append('head')\n",
    "\n",
    "# Verify that each module exists in the model:\n",
    "model_modules = dict(underlying_model.named_modules())\n",
    "for layer in layers:\n",
    "    if layer not in model_modules:\n",
    "        print(f\"Warning: {layer} not found in the model!\")\n",
    "    # You could also choose to remove it or handle it differently if needed.\n",
    "\n",
    "# Create an input tensor for testing (e.g., a random image tensor of size 224x224)\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Use NeuroElectrodeArray to extract activations from the specified layers:\n",
    "with NeuroElectrodeArray(underlying_model, layers=layers) as electrode:\n",
    "    activations = electrode(input_tensor)\n",
    "\n",
    "# Print the activation shapes for verification:\n",
    "for layer_name, activation in activations.items():\n",
    "    print(f\"Layer: {layer_name}, Shape: {activation.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "underlying_model = convnext_large.activations_model._model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():    \n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m nk.NeuroElectrodeArray(underlying_model, layers) \u001b[38;5;28;01mas\u001b[39;00m electrode:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         activations = \u001b[43melectrode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_name, act \u001b[38;5;129;01min\u001b[39;00m activations.items():\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(layer_name, act.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/neuroai_kit/electrode.py:86\u001b[39m, in \u001b[36mNeuroElectrodeArray.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._activations\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/timm/models/convnext.py:507\u001b[39m, in \u001b[36mConvNeXt.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.forward_head(x)\n\u001b[32m    509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/timm/models/convnext.py:498\u001b[39m, in \u001b[36mConvNeXt.forward_features\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.stages(x)\n\u001b[32m    500\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm_pre(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/nn/modules/module.py:1845\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1847\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1848\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1849\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1850\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/nn/modules/module.py:1793\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1790\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1791\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1795\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1796\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1797\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m   1799\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: conv2d() received an invalid combination of arguments - got (NoneType, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n"
     ]
    }
   ],
   "source": [
    "import neuroai_kit as nk\n",
    "# now adding my images\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print(f\"Using device: {device}\")\n",
    "# Load dataset\n",
    "dataset_path = \"s3://visionlab-litdata/exploring-objects-images/\"\n",
    "# moves imgs to GPU before running loops to extract activations\n",
    "img_batch = load_data(dataset_path)# this moves images to GPU early\n",
    "underlying_model.eval()\n",
    "with torch.no_grad():    \n",
    "    with nk.NeuroElectrodeArray(underlying_model, layers) as electrode:\n",
    "        activations = electrode(img_batch)\n",
    "for layer_name, act in activations.items():\n",
    "    print(layer_name, act.shape)\n",
    "\n",
    "\n",
    "# getting avg brain rdms for this new studio\n",
    "load_neural_data(filename = '/teamspace/uploads/ExploringObjectsData_SECTORS.mat' )\n",
    "reliable_betas_dict, rdm_dict = process_brain_data(data, threshold = 0.30, regions =None)\n",
    "clean_rdm_dict = compute_reliable_rdms(rdm_dict)\n",
    "#noise_ceiling_dict, avg_rdm_dict = \n",
    "noise_ceiling_dict, avg_rdm_dict = new_noise_ceiling(clean_rdm_dict, num_splits=100, seed=42)\n",
    "\n",
    "# Define base output folder\n",
    "base_output_folder = \"results\"\n",
    "os.makedirs(base_output_folder, exist_ok=True)\n",
    "\n",
    "# Create subfolder for average brain RDMs by ROI\n",
    "avg_rdm_folder = os.path.join(base_output_folder, \"avg_brain_rdms\")\n",
    "os.makedirs(avg_rdm_folder, exist_ok=True)\n",
    "\n",
    "# Save avg_rdm_dict: one file per ROI\n",
    "for roi, avg_rdm in avg_rdm_dict.items():\n",
    "    output_file = os.path.join(avg_rdm_folder, f\"{roi}_avg_rdm.pkl\")\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(avg_rdm, f)\n",
    "    print(f\"Saved avg RDM for {roi} in {output_file}\")\n",
    "\n",
    "# Create subfolder for noise ceiling dictionary by ROI\n",
    "nc_folder = os.path.join(base_output_folder, \"noise_ceiling\")\n",
    "os.makedirs(nc_folder, exist_ok=True)\n",
    "\n",
    "# Save noise_ceiling_dict: one file per ROI\n",
    "for roi, noise_ceiling in noise_ceiling_dict.items():\n",
    "    output_file = os.path.join(nc_folder, f\"{roi}_noise_ceiling.pkl\")\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(noise_ceiling, f)\n",
    "    print(f\"Saved noise ceiling for {roi} in {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving avg rdms by brain ROI in this new studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_neural_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# getting avg brain rdms for this new studio\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mload_neural_data\u001b[49m(filename = \u001b[33m'\u001b[39m\u001b[33m/teamspace/uploads/ExploringObjectsData_SECTORS.mat\u001b[39m\u001b[33m'\u001b[39m )\n\u001b[32m      3\u001b[39m reliable_betas_dict, rdm_dict = process_brain_data(data, threshold = \u001b[32m0.30\u001b[39m, regions =\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      4\u001b[39m clean_rdm_dict = compute_reliable_rdms(rdm_dict)\n",
      "\u001b[31mNameError\u001b[39m: name 'load_neural_data' is not defined"
     ]
    }
   ],
   "source": [
    "# getting avg brain rdms for this new studio\n",
    "load_neural_data(filename = '/teamspace/uploads/ExploringObjectsData_SECTORS.mat' )\n",
    "reliable_betas_dict, rdm_dict = process_brain_data(data, threshold = 0.30, regions =None)\n",
    "clean_rdm_dict = compute_reliable_rdms(rdm_dict)\n",
    "#noise_ceiling_dict, avg_rdm_dict = \n",
    "noise_ceiling_dict, avg_rdm_dict = new_noise_ceiling(clean_rdm_dict, num_splits=100, seed=42)\n",
    "\n",
    "# Define base output folder\n",
    "base_output_folder = \"results\"\n",
    "os.makedirs(base_output_folder, exist_ok=True)\n",
    "\n",
    "# Create subfolder for average brain RDMs by ROI\n",
    "avg_rdm_folder = os.path.join(base_output_folder, \"avg_brain_rdms\")\n",
    "os.makedirs(avg_rdm_folder, exist_ok=True)\n",
    "\n",
    "# Save avg_rdm_dict: one file per ROI\n",
    "for roi, avg_rdm in avg_rdm_dict.items():\n",
    "    output_file = os.path.join(avg_rdm_folder, f\"{roi}_avg_rdm.pkl\")\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(avg_rdm, f)\n",
    "    print(f\"Saved avg RDM for {roi} in {output_file}\")\n",
    "\n",
    "# Create subfolder for noise ceiling dictionary by ROI\n",
    "nc_folder = os.path.join(base_output_folder, \"noise_ceiling\")\n",
    "os.makedirs(nc_folder, exist_ok=True)\n",
    "\n",
    "# Save noise_ceiling_dict: one file per ROI\n",
    "for roi, noise_ceiling in noise_ceiling_dict.items():\n",
    "    output_file = os.path.join(nc_folder, f\"{roi}_noise_ceiling.pkl\")\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(noise_ceiling, f)\n",
    "    print(f\"Saved noise ceiling for {roi} in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from neuroai_kit.electrode import NeuroElectrodeArray\n",
    "\n",
    "# -------------------------\n",
    "# 1. Define and flatten layer names\n",
    "# -------------------------\n",
    "layers = []\n",
    "\n",
    "# Add stem layer\n",
    "layers.append('stem')\n",
    "\n",
    "# Add stages and block-level layers\n",
    "for stage_idx in range(4):  # stages 0,1,2,3\n",
    "    stage_name = f\"stages.{stage_idx}\"\n",
    "    layers.append(stage_name)  # include the entire stage if desired\n",
    "\n",
    "    # Determine the number of blocks: stage 2 has 27 blocks, others have 3 blocks each.\n",
    "    num_blocks = 27 if stage_idx == 2 else 3\n",
    "    for block_idx in range(num_blocks):\n",
    "        block_prefix = f\"{stage_name}.blocks.{block_idx}\"\n",
    "        # Add key activation points in the block (MLP activation, normalization, and block output)\n",
    "        layers.append(f\"{block_prefix}.mlp.act\")\n",
    "        layers.append(f\"{block_prefix}.norm\")\n",
    "        layers.append(block_prefix)\n",
    "\n",
    "# Add the head of the model\n",
    "layers.append('head')\n",
    "\n",
    "# -------------------------\n",
    "# 2. Verify modules exist\n",
    "# -------------------------\n",
    "# Assume underlying_model is your PyTorch model, e.g.:\n",
    "underlying_model = convnext_large.activations_model._model  # adjust as needed\n",
    "\n",
    "model_modules = dict(underlying_model.named_modules())\n",
    "for layer in layers:\n",
    "    if layer not in model_modules:\n",
    "        print(f\"Warning: {layer} not found in the model!\")\n",
    "\n",
    "# -------------------------\n",
    "# 3. Extract activations using NeuroElectrodeArray\n",
    "# -------------------------\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "with NeuroElectrodeArray(underlying_model, layers=layers) as electrode:\n",
    "    activations = electrode(input_tensor)\n",
    "\n",
    "# -------------------------\n",
    "# 4. Prepare data for visualization\n",
    "# -------------------------\n",
    "layer_names = list(activations.keys())\n",
    "channel_counts = []\n",
    "# Also determine the stage for color-coding:\n",
    "stages = []\n",
    "\n",
    "for name in layer_names:\n",
    "    shape = activations[name].shape\n",
    "    # We assume activations are either 4D ([batch, channels, H, W]) or 2D ([batch, features])\n",
    "    ch = shape[1] if len(shape) >= 2 else 0\n",
    "    channel_counts.append(ch)\n",
    "    \n",
    "    # Determine stage based on name:\n",
    "    if name.startswith(\"stem\"):\n",
    "        stages.append(\"stem\")\n",
    "    elif \"stages.0\" in name:\n",
    "        stages.append(\"stage 0\")\n",
    "    elif \"stages.1\" in name:\n",
    "        stages.append(\"stage 1\")\n",
    "    elif \"stages.2\" in name:\n",
    "        stages.append(\"stage 2\")\n",
    "    elif \"stages.3\" in name:\n",
    "        stages.append(\"stage 3\")\n",
    "    elif name.startswith(\"head\"):\n",
    "        stages.append(\"head\")\n",
    "    else:\n",
    "        stages.append(\"other\")\n",
    "\n",
    "# Map each stage to a color using a colormap:\n",
    "unique_stages = sorted(list(set(stages)))\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(unique_stages)))\n",
    "stage_color_map = dict(zip(unique_stages, colors))\n",
    "layer_colors = [stage_color_map[s] for s in stages]\n",
    "\n",
    "# -------------------------\n",
    "# 5. Create the visualization\n",
    "# -------------------------\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.bar(range(len(channel_counts)), channel_counts, color=layer_colors)\n",
    "plt.xlabel(\"Layer (ordered by forward pass)\")\n",
    "plt.ylabel(\"Activation Channels\")\n",
    "plt.title(\"Activation Channel Count per Layer\")\n",
    "\n",
    "# Optionally, add layer names as x-tick labels (rotated for readability)\n",
    "plt.xticks(range(len(channel_counts)), layer_names, rotation=90, fontsize=8)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create a legend for stages\n",
    "handles = [plt.Rectangle((0, 0), 1, 1, color=stage_color_map[s]) for s in unique_stages]\n",
    "plt.legend(handles, unique_stages, title=\"Stages\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'blocks'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m input_tensor = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Extract activations using the electrode\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNeuroElectrodeArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43munderlying_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melectrode\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43melectrode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Now you can access the activations\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/neuroai_kit/electrode.py:59\u001b[39m, in \u001b[36mNeuroElectrodeArray.__enter__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args): \n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhook_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/neuroai_kit/electrode.py:47\u001b[39m, in \u001b[36mNeuroElectrodeArray.hook_layers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mself\u001b[39m.remove_hooks()\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     layer = \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnamed_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mself\u001b[39m.hooks[layer_id] = layer.register_forward_hook(\u001b[38;5;28mself\u001b[39m.save_outputs_hook(layer_id))\n",
      "\u001b[31mKeyError\u001b[39m: 'blocks'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Get the underlying PyTorch model from the wrapper\n",
    "underlying_model = convnext_large.activations_model._model  # Note the underscore in _model\n",
    "\n",
    "# Now use the NeuroElectrodeArray with the unwrapped model\n",
    "from neuroai_kit.electrode import NeuroElectrodeArray\n",
    "\n",
    "# # Define the layers you want to extract\n",
    "# layers = [\n",
    "#     'stem',\n",
    "#     'stages.0',\n",
    "#     'stages.1',\n",
    "#     'stages.2',\n",
    "#     'stages.3',\n",
    "#     'head'\n",
    "#     # Add more specific layers as needed\n",
    "# ]\n",
    "layers = {\n",
    "#     'stem': 'stem',\n",
    "#     'stages': ['stages.0', 'stages.1', 'stages.2', 'stages.3'],\n",
    "#     'blocks': {\n",
    "#         'stages.0': [f'stages.0.blocks.{i}' for i in range(3)],\n",
    "#         'stages.1': [f'stages.1.blocks.{i}' for i in range(3)],\n",
    "#         'stages.2': [f'stages.2.blocks.{i}' for i in range(27)],\n",
    "#         'stages.3': [f'stages.3.blocks.{i}' for i in range(3)]\n",
    "#     },\n",
    "#     'head': 'head'\n",
    "# }\n",
    "# Create input tensor for testing\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Extract activations using the electrode\n",
    "with NeuroElectrodeArray(underlying_model, layers=layers) as electrode:\n",
    "    activations = electrode(input_tensor)\n",
    "\n",
    "# Now you can access the activations\n",
    "for layer_name, activation in activations.items():\n",
    "    print(f\"Layer: {layer_name}, Shape: {activation.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convnext_large' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mconvnext_large\u001b[49m.layers)\n",
      "\u001b[31mNameError\u001b[39m: name 'convnext_large' is not defined"
     ]
    }
   ],
   "source": [
    "print(convnext_large.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# downloading raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 192, 96, 96])\n",
      "torch.Size([1, 384, 48, 48])\n",
      "torch.Size([1, 768, 24, 24])\n",
      "torch.Size([1, 1536, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n",
    "\n",
    "model = timm.create_model(\n",
    "    'convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384',\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 192, 96, 96])\n",
    "    #  torch.Size([1, 384, 48, 48])\n",
    "    #  torch.Size([1, 768, 24, 24])\n",
    "    #  torch.Size([1, 1536, 12, 12])\n",
    "\n",
    "    print(o.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stem_0\n",
      "stem_1\n",
      "stages_0\n",
      "stages_0.downsample\n",
      "stages_0.blocks\n",
      "stages_0.blocks.0\n",
      "stages_0.blocks.0.conv_dw\n",
      "stages_0.blocks.0.norm\n",
      "stages_0.blocks.0.mlp\n",
      "stages_0.blocks.0.mlp.fc1\n",
      "stages_0.blocks.0.mlp.act\n",
      "stages_0.blocks.0.mlp.drop1\n",
      "stages_0.blocks.0.mlp.norm\n",
      "stages_0.blocks.0.mlp.fc2\n",
      "stages_0.blocks.0.mlp.drop2\n",
      "stages_0.blocks.0.shortcut\n",
      "stages_0.blocks.0.drop_path\n",
      "stages_0.blocks.1\n",
      "stages_0.blocks.1.conv_dw\n",
      "stages_0.blocks.1.norm\n",
      "stages_0.blocks.1.mlp\n",
      "stages_0.blocks.1.mlp.fc1\n",
      "stages_0.blocks.1.mlp.act\n",
      "stages_0.blocks.1.mlp.drop1\n",
      "stages_0.blocks.1.mlp.norm\n",
      "stages_0.blocks.1.mlp.fc2\n",
      "stages_0.blocks.1.mlp.drop2\n",
      "stages_0.blocks.1.shortcut\n",
      "stages_0.blocks.1.drop_path\n",
      "stages_0.blocks.2\n",
      "stages_0.blocks.2.conv_dw\n",
      "stages_0.blocks.2.norm\n",
      "stages_0.blocks.2.mlp\n",
      "stages_0.blocks.2.mlp.fc1\n",
      "stages_0.blocks.2.mlp.act\n",
      "stages_0.blocks.2.mlp.drop1\n",
      "stages_0.blocks.2.mlp.norm\n",
      "stages_0.blocks.2.mlp.fc2\n",
      "stages_0.blocks.2.mlp.drop2\n",
      "stages_0.blocks.2.shortcut\n",
      "stages_0.blocks.2.drop_path\n",
      "stages_1\n",
      "stages_1.downsample\n",
      "stages_1.downsample.0\n",
      "stages_1.downsample.1\n",
      "stages_1.blocks\n",
      "stages_1.blocks.0\n",
      "stages_1.blocks.0.conv_dw\n",
      "stages_1.blocks.0.norm\n",
      "stages_1.blocks.0.mlp\n",
      "stages_1.blocks.0.mlp.fc1\n",
      "stages_1.blocks.0.mlp.act\n",
      "stages_1.blocks.0.mlp.drop1\n",
      "stages_1.blocks.0.mlp.norm\n",
      "stages_1.blocks.0.mlp.fc2\n",
      "stages_1.blocks.0.mlp.drop2\n",
      "stages_1.blocks.0.shortcut\n",
      "stages_1.blocks.0.drop_path\n",
      "stages_1.blocks.1\n",
      "stages_1.blocks.1.conv_dw\n",
      "stages_1.blocks.1.norm\n",
      "stages_1.blocks.1.mlp\n",
      "stages_1.blocks.1.mlp.fc1\n",
      "stages_1.blocks.1.mlp.act\n",
      "stages_1.blocks.1.mlp.drop1\n",
      "stages_1.blocks.1.mlp.norm\n",
      "stages_1.blocks.1.mlp.fc2\n",
      "stages_1.blocks.1.mlp.drop2\n",
      "stages_1.blocks.1.shortcut\n",
      "stages_1.blocks.1.drop_path\n",
      "stages_1.blocks.2\n",
      "stages_1.blocks.2.conv_dw\n",
      "stages_1.blocks.2.norm\n",
      "stages_1.blocks.2.mlp\n",
      "stages_1.blocks.2.mlp.fc1\n",
      "stages_1.blocks.2.mlp.act\n",
      "stages_1.blocks.2.mlp.drop1\n",
      "stages_1.blocks.2.mlp.norm\n",
      "stages_1.blocks.2.mlp.fc2\n",
      "stages_1.blocks.2.mlp.drop2\n",
      "stages_1.blocks.2.shortcut\n",
      "stages_1.blocks.2.drop_path\n",
      "stages_2\n",
      "stages_2.downsample\n",
      "stages_2.downsample.0\n",
      "stages_2.downsample.1\n",
      "stages_2.blocks\n",
      "stages_2.blocks.0\n",
      "stages_2.blocks.0.conv_dw\n",
      "stages_2.blocks.0.norm\n",
      "stages_2.blocks.0.mlp\n",
      "stages_2.blocks.0.mlp.fc1\n",
      "stages_2.blocks.0.mlp.act\n",
      "stages_2.blocks.0.mlp.drop1\n",
      "stages_2.blocks.0.mlp.norm\n",
      "stages_2.blocks.0.mlp.fc2\n",
      "stages_2.blocks.0.mlp.drop2\n",
      "stages_2.blocks.0.shortcut\n",
      "stages_2.blocks.0.drop_path\n",
      "stages_2.blocks.1\n",
      "stages_2.blocks.1.conv_dw\n",
      "stages_2.blocks.1.norm\n",
      "stages_2.blocks.1.mlp\n",
      "stages_2.blocks.1.mlp.fc1\n",
      "stages_2.blocks.1.mlp.act\n",
      "stages_2.blocks.1.mlp.drop1\n",
      "stages_2.blocks.1.mlp.norm\n",
      "stages_2.blocks.1.mlp.fc2\n",
      "stages_2.blocks.1.mlp.drop2\n",
      "stages_2.blocks.1.shortcut\n",
      "stages_2.blocks.1.drop_path\n",
      "stages_2.blocks.2\n",
      "stages_2.blocks.2.conv_dw\n",
      "stages_2.blocks.2.norm\n",
      "stages_2.blocks.2.mlp\n",
      "stages_2.blocks.2.mlp.fc1\n",
      "stages_2.blocks.2.mlp.act\n",
      "stages_2.blocks.2.mlp.drop1\n",
      "stages_2.blocks.2.mlp.norm\n",
      "stages_2.blocks.2.mlp.fc2\n",
      "stages_2.blocks.2.mlp.drop2\n",
      "stages_2.blocks.2.shortcut\n",
      "stages_2.blocks.2.drop_path\n",
      "stages_2.blocks.3\n",
      "stages_2.blocks.3.conv_dw\n",
      "stages_2.blocks.3.norm\n",
      "stages_2.blocks.3.mlp\n",
      "stages_2.blocks.3.mlp.fc1\n",
      "stages_2.blocks.3.mlp.act\n",
      "stages_2.blocks.3.mlp.drop1\n",
      "stages_2.blocks.3.mlp.norm\n",
      "stages_2.blocks.3.mlp.fc2\n",
      "stages_2.blocks.3.mlp.drop2\n",
      "stages_2.blocks.3.shortcut\n",
      "stages_2.blocks.3.drop_path\n",
      "stages_2.blocks.4\n",
      "stages_2.blocks.4.conv_dw\n",
      "stages_2.blocks.4.norm\n",
      "stages_2.blocks.4.mlp\n",
      "stages_2.blocks.4.mlp.fc1\n",
      "stages_2.blocks.4.mlp.act\n",
      "stages_2.blocks.4.mlp.drop1\n",
      "stages_2.blocks.4.mlp.norm\n",
      "stages_2.blocks.4.mlp.fc2\n",
      "stages_2.blocks.4.mlp.drop2\n",
      "stages_2.blocks.4.shortcut\n",
      "stages_2.blocks.4.drop_path\n",
      "stages_2.blocks.5\n",
      "stages_2.blocks.5.conv_dw\n",
      "stages_2.blocks.5.norm\n",
      "stages_2.blocks.5.mlp\n",
      "stages_2.blocks.5.mlp.fc1\n",
      "stages_2.blocks.5.mlp.act\n",
      "stages_2.blocks.5.mlp.drop1\n",
      "stages_2.blocks.5.mlp.norm\n",
      "stages_2.blocks.5.mlp.fc2\n",
      "stages_2.blocks.5.mlp.drop2\n",
      "stages_2.blocks.5.shortcut\n",
      "stages_2.blocks.5.drop_path\n",
      "stages_2.blocks.6\n",
      "stages_2.blocks.6.conv_dw\n",
      "stages_2.blocks.6.norm\n",
      "stages_2.blocks.6.mlp\n",
      "stages_2.blocks.6.mlp.fc1\n",
      "stages_2.blocks.6.mlp.act\n",
      "stages_2.blocks.6.mlp.drop1\n",
      "stages_2.blocks.6.mlp.norm\n",
      "stages_2.blocks.6.mlp.fc2\n",
      "stages_2.blocks.6.mlp.drop2\n",
      "stages_2.blocks.6.shortcut\n",
      "stages_2.blocks.6.drop_path\n",
      "stages_2.blocks.7\n",
      "stages_2.blocks.7.conv_dw\n",
      "stages_2.blocks.7.norm\n",
      "stages_2.blocks.7.mlp\n",
      "stages_2.blocks.7.mlp.fc1\n",
      "stages_2.blocks.7.mlp.act\n",
      "stages_2.blocks.7.mlp.drop1\n",
      "stages_2.blocks.7.mlp.norm\n",
      "stages_2.blocks.7.mlp.fc2\n",
      "stages_2.blocks.7.mlp.drop2\n",
      "stages_2.blocks.7.shortcut\n",
      "stages_2.blocks.7.drop_path\n",
      "stages_2.blocks.8\n",
      "stages_2.blocks.8.conv_dw\n",
      "stages_2.blocks.8.norm\n",
      "stages_2.blocks.8.mlp\n",
      "stages_2.blocks.8.mlp.fc1\n",
      "stages_2.blocks.8.mlp.act\n",
      "stages_2.blocks.8.mlp.drop1\n",
      "stages_2.blocks.8.mlp.norm\n",
      "stages_2.blocks.8.mlp.fc2\n",
      "stages_2.blocks.8.mlp.drop2\n",
      "stages_2.blocks.8.shortcut\n",
      "stages_2.blocks.8.drop_path\n",
      "stages_2.blocks.9\n",
      "stages_2.blocks.9.conv_dw\n",
      "stages_2.blocks.9.norm\n",
      "stages_2.blocks.9.mlp\n",
      "stages_2.blocks.9.mlp.fc1\n",
      "stages_2.blocks.9.mlp.act\n",
      "stages_2.blocks.9.mlp.drop1\n",
      "stages_2.blocks.9.mlp.norm\n",
      "stages_2.blocks.9.mlp.fc2\n",
      "stages_2.blocks.9.mlp.drop2\n",
      "stages_2.blocks.9.shortcut\n",
      "stages_2.blocks.9.drop_path\n",
      "stages_2.blocks.10\n",
      "stages_2.blocks.10.conv_dw\n",
      "stages_2.blocks.10.norm\n",
      "stages_2.blocks.10.mlp\n",
      "stages_2.blocks.10.mlp.fc1\n",
      "stages_2.blocks.10.mlp.act\n",
      "stages_2.blocks.10.mlp.drop1\n",
      "stages_2.blocks.10.mlp.norm\n",
      "stages_2.blocks.10.mlp.fc2\n",
      "stages_2.blocks.10.mlp.drop2\n",
      "stages_2.blocks.10.shortcut\n",
      "stages_2.blocks.10.drop_path\n",
      "stages_2.blocks.11\n",
      "stages_2.blocks.11.conv_dw\n",
      "stages_2.blocks.11.norm\n",
      "stages_2.blocks.11.mlp\n",
      "stages_2.blocks.11.mlp.fc1\n",
      "stages_2.blocks.11.mlp.act\n",
      "stages_2.blocks.11.mlp.drop1\n",
      "stages_2.blocks.11.mlp.norm\n",
      "stages_2.blocks.11.mlp.fc2\n",
      "stages_2.blocks.11.mlp.drop2\n",
      "stages_2.blocks.11.shortcut\n",
      "stages_2.blocks.11.drop_path\n",
      "stages_2.blocks.12\n",
      "stages_2.blocks.12.conv_dw\n",
      "stages_2.blocks.12.norm\n",
      "stages_2.blocks.12.mlp\n",
      "stages_2.blocks.12.mlp.fc1\n",
      "stages_2.blocks.12.mlp.act\n",
      "stages_2.blocks.12.mlp.drop1\n",
      "stages_2.blocks.12.mlp.norm\n",
      "stages_2.blocks.12.mlp.fc2\n",
      "stages_2.blocks.12.mlp.drop2\n",
      "stages_2.blocks.12.shortcut\n",
      "stages_2.blocks.12.drop_path\n",
      "stages_2.blocks.13\n",
      "stages_2.blocks.13.conv_dw\n",
      "stages_2.blocks.13.norm\n",
      "stages_2.blocks.13.mlp\n",
      "stages_2.blocks.13.mlp.fc1\n",
      "stages_2.blocks.13.mlp.act\n",
      "stages_2.blocks.13.mlp.drop1\n",
      "stages_2.blocks.13.mlp.norm\n",
      "stages_2.blocks.13.mlp.fc2\n",
      "stages_2.blocks.13.mlp.drop2\n",
      "stages_2.blocks.13.shortcut\n",
      "stages_2.blocks.13.drop_path\n",
      "stages_2.blocks.14\n",
      "stages_2.blocks.14.conv_dw\n",
      "stages_2.blocks.14.norm\n",
      "stages_2.blocks.14.mlp\n",
      "stages_2.blocks.14.mlp.fc1\n",
      "stages_2.blocks.14.mlp.act\n",
      "stages_2.blocks.14.mlp.drop1\n",
      "stages_2.blocks.14.mlp.norm\n",
      "stages_2.blocks.14.mlp.fc2\n",
      "stages_2.blocks.14.mlp.drop2\n",
      "stages_2.blocks.14.shortcut\n",
      "stages_2.blocks.14.drop_path\n",
      "stages_2.blocks.15\n",
      "stages_2.blocks.15.conv_dw\n",
      "stages_2.blocks.15.norm\n",
      "stages_2.blocks.15.mlp\n",
      "stages_2.blocks.15.mlp.fc1\n",
      "stages_2.blocks.15.mlp.act\n",
      "stages_2.blocks.15.mlp.drop1\n",
      "stages_2.blocks.15.mlp.norm\n",
      "stages_2.blocks.15.mlp.fc2\n",
      "stages_2.blocks.15.mlp.drop2\n",
      "stages_2.blocks.15.shortcut\n",
      "stages_2.blocks.15.drop_path\n",
      "stages_2.blocks.16\n",
      "stages_2.blocks.16.conv_dw\n",
      "stages_2.blocks.16.norm\n",
      "stages_2.blocks.16.mlp\n",
      "stages_2.blocks.16.mlp.fc1\n",
      "stages_2.blocks.16.mlp.act\n",
      "stages_2.blocks.16.mlp.drop1\n",
      "stages_2.blocks.16.mlp.norm\n",
      "stages_2.blocks.16.mlp.fc2\n",
      "stages_2.blocks.16.mlp.drop2\n",
      "stages_2.blocks.16.shortcut\n",
      "stages_2.blocks.16.drop_path\n",
      "stages_2.blocks.17\n",
      "stages_2.blocks.17.conv_dw\n",
      "stages_2.blocks.17.norm\n",
      "stages_2.blocks.17.mlp\n",
      "stages_2.blocks.17.mlp.fc1\n",
      "stages_2.blocks.17.mlp.act\n",
      "stages_2.blocks.17.mlp.drop1\n",
      "stages_2.blocks.17.mlp.norm\n",
      "stages_2.blocks.17.mlp.fc2\n",
      "stages_2.blocks.17.mlp.drop2\n",
      "stages_2.blocks.17.shortcut\n",
      "stages_2.blocks.17.drop_path\n",
      "stages_2.blocks.18\n",
      "stages_2.blocks.18.conv_dw\n",
      "stages_2.blocks.18.norm\n",
      "stages_2.blocks.18.mlp\n",
      "stages_2.blocks.18.mlp.fc1\n",
      "stages_2.blocks.18.mlp.act\n",
      "stages_2.blocks.18.mlp.drop1\n",
      "stages_2.blocks.18.mlp.norm\n",
      "stages_2.blocks.18.mlp.fc2\n",
      "stages_2.blocks.18.mlp.drop2\n",
      "stages_2.blocks.18.shortcut\n",
      "stages_2.blocks.18.drop_path\n",
      "stages_2.blocks.19\n",
      "stages_2.blocks.19.conv_dw\n",
      "stages_2.blocks.19.norm\n",
      "stages_2.blocks.19.mlp\n",
      "stages_2.blocks.19.mlp.fc1\n",
      "stages_2.blocks.19.mlp.act\n",
      "stages_2.blocks.19.mlp.drop1\n",
      "stages_2.blocks.19.mlp.norm\n",
      "stages_2.blocks.19.mlp.fc2\n",
      "stages_2.blocks.19.mlp.drop2\n",
      "stages_2.blocks.19.shortcut\n",
      "stages_2.blocks.19.drop_path\n",
      "stages_2.blocks.20\n",
      "stages_2.blocks.20.conv_dw\n",
      "stages_2.blocks.20.norm\n",
      "stages_2.blocks.20.mlp\n",
      "stages_2.blocks.20.mlp.fc1\n",
      "stages_2.blocks.20.mlp.act\n",
      "stages_2.blocks.20.mlp.drop1\n",
      "stages_2.blocks.20.mlp.norm\n",
      "stages_2.blocks.20.mlp.fc2\n",
      "stages_2.blocks.20.mlp.drop2\n",
      "stages_2.blocks.20.shortcut\n",
      "stages_2.blocks.20.drop_path\n",
      "stages_2.blocks.21\n",
      "stages_2.blocks.21.conv_dw\n",
      "stages_2.blocks.21.norm\n",
      "stages_2.blocks.21.mlp\n",
      "stages_2.blocks.21.mlp.fc1\n",
      "stages_2.blocks.21.mlp.act\n",
      "stages_2.blocks.21.mlp.drop1\n",
      "stages_2.blocks.21.mlp.norm\n",
      "stages_2.blocks.21.mlp.fc2\n",
      "stages_2.blocks.21.mlp.drop2\n",
      "stages_2.blocks.21.shortcut\n",
      "stages_2.blocks.21.drop_path\n",
      "stages_2.blocks.22\n",
      "stages_2.blocks.22.conv_dw\n",
      "stages_2.blocks.22.norm\n",
      "stages_2.blocks.22.mlp\n",
      "stages_2.blocks.22.mlp.fc1\n",
      "stages_2.blocks.22.mlp.act\n",
      "stages_2.blocks.22.mlp.drop1\n",
      "stages_2.blocks.22.mlp.norm\n",
      "stages_2.blocks.22.mlp.fc2\n",
      "stages_2.blocks.22.mlp.drop2\n",
      "stages_2.blocks.22.shortcut\n",
      "stages_2.blocks.22.drop_path\n",
      "stages_2.blocks.23\n",
      "stages_2.blocks.23.conv_dw\n",
      "stages_2.blocks.23.norm\n",
      "stages_2.blocks.23.mlp\n",
      "stages_2.blocks.23.mlp.fc1\n",
      "stages_2.blocks.23.mlp.act\n",
      "stages_2.blocks.23.mlp.drop1\n",
      "stages_2.blocks.23.mlp.norm\n",
      "stages_2.blocks.23.mlp.fc2\n",
      "stages_2.blocks.23.mlp.drop2\n",
      "stages_2.blocks.23.shortcut\n",
      "stages_2.blocks.23.drop_path\n",
      "stages_2.blocks.24\n",
      "stages_2.blocks.24.conv_dw\n",
      "stages_2.blocks.24.norm\n",
      "stages_2.blocks.24.mlp\n",
      "stages_2.blocks.24.mlp.fc1\n",
      "stages_2.blocks.24.mlp.act\n",
      "stages_2.blocks.24.mlp.drop1\n",
      "stages_2.blocks.24.mlp.norm\n",
      "stages_2.blocks.24.mlp.fc2\n",
      "stages_2.blocks.24.mlp.drop2\n",
      "stages_2.blocks.24.shortcut\n",
      "stages_2.blocks.24.drop_path\n",
      "stages_2.blocks.25\n",
      "stages_2.blocks.25.conv_dw\n",
      "stages_2.blocks.25.norm\n",
      "stages_2.blocks.25.mlp\n",
      "stages_2.blocks.25.mlp.fc1\n",
      "stages_2.blocks.25.mlp.act\n",
      "stages_2.blocks.25.mlp.drop1\n",
      "stages_2.blocks.25.mlp.norm\n",
      "stages_2.blocks.25.mlp.fc2\n",
      "stages_2.blocks.25.mlp.drop2\n",
      "stages_2.blocks.25.shortcut\n",
      "stages_2.blocks.25.drop_path\n",
      "stages_2.blocks.26\n",
      "stages_2.blocks.26.conv_dw\n",
      "stages_2.blocks.26.norm\n",
      "stages_2.blocks.26.mlp\n",
      "stages_2.blocks.26.mlp.fc1\n",
      "stages_2.blocks.26.mlp.act\n",
      "stages_2.blocks.26.mlp.drop1\n",
      "stages_2.blocks.26.mlp.norm\n",
      "stages_2.blocks.26.mlp.fc2\n",
      "stages_2.blocks.26.mlp.drop2\n",
      "stages_2.blocks.26.shortcut\n",
      "stages_2.blocks.26.drop_path\n",
      "stages_3\n",
      "stages_3.downsample\n",
      "stages_3.downsample.0\n",
      "stages_3.downsample.1\n",
      "stages_3.blocks\n",
      "stages_3.blocks.0\n",
      "stages_3.blocks.0.conv_dw\n",
      "stages_3.blocks.0.norm\n",
      "stages_3.blocks.0.mlp\n",
      "stages_3.blocks.0.mlp.fc1\n",
      "stages_3.blocks.0.mlp.act\n",
      "stages_3.blocks.0.mlp.drop1\n",
      "stages_3.blocks.0.mlp.norm\n",
      "stages_3.blocks.0.mlp.fc2\n",
      "stages_3.blocks.0.mlp.drop2\n",
      "stages_3.blocks.0.shortcut\n",
      "stages_3.blocks.0.drop_path\n",
      "stages_3.blocks.1\n",
      "stages_3.blocks.1.conv_dw\n",
      "stages_3.blocks.1.norm\n",
      "stages_3.blocks.1.mlp\n",
      "stages_3.blocks.1.mlp.fc1\n",
      "stages_3.blocks.1.mlp.act\n",
      "stages_3.blocks.1.mlp.drop1\n",
      "stages_3.blocks.1.mlp.norm\n",
      "stages_3.blocks.1.mlp.fc2\n",
      "stages_3.blocks.1.mlp.drop2\n",
      "stages_3.blocks.1.shortcut\n",
      "stages_3.blocks.1.drop_path\n",
      "stages_3.blocks.2\n",
      "stages_3.blocks.2.conv_dw\n",
      "stages_3.blocks.2.norm\n",
      "stages_3.blocks.2.mlp\n",
      "stages_3.blocks.2.mlp.fc1\n",
      "stages_3.blocks.2.mlp.act\n",
      "stages_3.blocks.2.mlp.drop1\n",
      "stages_3.blocks.2.mlp.norm\n",
      "stages_3.blocks.2.mlp.fc2\n",
      "stages_3.blocks.2.mlp.drop2\n",
      "stages_3.blocks.2.shortcut\n",
      "stages_3.blocks.2.drop_path\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(name)\n",
    "    # print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict([*model.named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_outputs_hook(layer_id):\n",
    "    def detach(output):\n",
    "        if isinstance(output, tuple): return tuple([o.detach() for o in output])\n",
    "        elif isinstance(output, list): return [o.detach() for o in output]\n",
    "        else: return output.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7fef9cd54510>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = dict([*model.named_modules()])['stages_2.blocks.4.conv_dw']\n",
    "layer.register_forward_hook(save_outputs_hook('stages_2.blocks.4.conv_dw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'brainscore_vision.model_helpers.activations.pytorch.PytorchWrapper'>\n",
      "['__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_build_extractor', '_device', '_extractor', '_forward_kwargs', '_model', '_output_layer', '_tensor_to_numpy', 'from_paths', 'from_stimulus_set', 'get_activations', 'get_layer', 'graph', 'identifier', 'layers', 'register_batch_activations_hook', 'register_hook', 'register_stimulus_set_hook']\n"
     ]
    }
   ],
   "source": [
    "print(type(convnext_large.activations_model))\n",
    "print(dir(convnext_large.activations_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stages.2.blocks.4.conv_dw', 'stages.2.blocks.3', 'stages.2.blocks.4.conv_dw', 'stages.2.downsample.1', 'head.pre_logits']\n"
     ]
    }
   ],
   "source": [
    "print(convnext_large.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(isinstance(convnext_large.activations_model, torch.nn.Module))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuroai_kit as nk\n",
    "from neuroai_kit import model_utils\n",
    "from neuroai_kit.electrode import NeuroElectrodeArray\n",
    "\n",
    "layers = {\n",
    "    'stem': 'stem',\n",
    "    'stages': ['stages.0', 'stages.1', 'stages.2', 'stages.3'],\n",
    "    'blocks': {\n",
    "        'stages.0': [f'stages.0.blocks.{i}' for i in range(3)],\n",
    "        'stages.1': [f'stages.1.blocks.{i}' for i in range(3)],\n",
    "        'stages.2': [f'stages.2.blocks.{i}' for i in range(27)],\n",
    "        'stages.3': [f'stages.3.blocks.{i}' for i in range(3)]\n",
    "    },\n",
    "    'head': 'head'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Could not get layer 'stem' using get_layer: 'ModelCommitment' object has no attribute 'get_layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mCustomNeuroElectrodeArray.hook_layers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     layer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_layer\u001b[49m(layer_id)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mAttributeError\u001b[39m: 'ModelCommitment' object has no attribute 'get_layer'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     49\u001b[39m input_tensor = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Now use your custom electrode class.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mCustomNeuroElectrodeArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvnext_large\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_layer_names\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melectrode\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43melectrode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Print activation shapes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/neuroai_kit/electrode.py:59\u001b[39m, in \u001b[36mNeuroElectrodeArray.__enter__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args): \n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhook_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mCustomNeuroElectrodeArray.hook_layers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     13\u001b[39m     layer = \u001b[38;5;28mself\u001b[39m.model.get_layer(layer_id)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not get layer \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m using get_layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mself\u001b[39m.hooks[layer_id] = layer.register_forward_hook(\u001b[38;5;28mself\u001b[39m.save_outputs_hook(layer_id))\n",
      "\u001b[31mAttributeError\u001b[39m: Could not get layer 'stem' using get_layer: 'ModelCommitment' object has no attribute 'get_layer'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import neuroai_kit as nk\n",
    "from neuroai_kit.electrode import NeuroElectrodeArray\n",
    "\n",
    "# Define your custom subclass that overrides hook_layers\n",
    "class CustomNeuroElectrodeArray(NeuroElectrodeArray):\n",
    "    def hook_layers(self):\n",
    "        # Remove any existing hooks\n",
    "        self.remove_hooks()\n",
    "        # Instead of iterating over named_modules(), use your model's get_layer method\n",
    "        for layer_id in self.layers:\n",
    "            try:\n",
    "                layer = self.model.get_layer(layer_id)\n",
    "            except Exception as e:\n",
    "                raise AttributeError(f\"Could not get layer '{layer_id}' using get_layer: {e}\")\n",
    "            self.hooks[layer_id] = layer.register_forward_hook(self.save_outputs_hook(layer_id))\n",
    "\n",
    "# Now define your layers dictionary manually. Adjust block counts to match your architecture.\n",
    "layers = {\n",
    "    'stem': 'stem',\n",
    "    'stages': ['stages.0', 'stages.1', 'stages.2', 'stages.3'],\n",
    "    'blocks': {\n",
    "        'stages.0': [f'stages.0.blocks.{i}' for i in range(3)],\n",
    "        'stages.1': [f'stages.1.blocks.{i}' for i in range(3)],\n",
    "        'stages.2': [f'stages.2.blocks.{i}' for i in range(27)],\n",
    "        'stages.3': [f'stages.3.blocks.{i}' for i in range(3)]\n",
    "    },\n",
    "    'head': 'head'\n",
    "}\n",
    "\n",
    "# Depending on how your model expects layer names, you might need to flatten the dictionary.\n",
    "# One simple strategy is to merge the keys into one list. For example:\n",
    "custom_layer_names = []\n",
    "\n",
    "# Add stem\n",
    "custom_layer_names.append(layers['stem'])\n",
    "\n",
    "# Add each stage and its blocks\n",
    "for stage in layers['stages']:\n",
    "    custom_layer_names.append(stage)\n",
    "    # Add blocks for the stage (if defined)\n",
    "    if stage in layers['blocks']:\n",
    "        custom_layer_names.extend(layers['blocks'][stage])\n",
    "\n",
    "# Add head\n",
    "custom_layer_names.append(layers['head'])\n",
    "\n",
    "# Create a dummy input tensor (adjust shape as needed)\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Now use your custom electrode class.\n",
    "with CustomNeuroElectrodeArray(convnext_large, layers=custom_layer_names) as electrode:\n",
    "    activations = electrode(input_tensor)\n",
    "\n",
    "# Print activation shapes\n",
    "print(\"Activation shapes:\")\n",
    "for layer_name, activation in activations.items():\n",
    "    print(f\"{layer_name}: {activation.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined layer mapping keys:\n",
      "stem\n",
      "stages.0\n",
      "stages.0.blocks.0\n",
      "stages.0.blocks.1\n",
      "stages.0.blocks.2\n",
      "stages.1\n",
      "stages.1.blocks.0\n",
      "stages.1.blocks.1\n",
      "stages.1.blocks.2\n",
      "stages.2\n",
      "stages.2.blocks.0\n",
      "stages.2.blocks.1\n",
      "stages.2.blocks.2\n",
      "stages.2.blocks.3\n",
      "stages.2.blocks.4\n",
      "stages.2.blocks.5\n",
      "stages.2.blocks.6\n",
      "stages.2.blocks.7\n",
      "stages.2.blocks.8\n",
      "stages.2.blocks.9\n",
      "stages.2.blocks.10\n",
      "stages.2.blocks.11\n",
      "stages.2.blocks.12\n",
      "stages.2.blocks.13\n",
      "stages.2.blocks.14\n",
      "stages.2.blocks.15\n",
      "stages.2.blocks.16\n",
      "stages.2.blocks.17\n",
      "stages.2.blocks.18\n",
      "stages.2.blocks.19\n",
      "stages.2.blocks.20\n",
      "stages.2.blocks.21\n",
      "stages.2.blocks.22\n",
      "stages.2.blocks.23\n",
      "stages.2.blocks.24\n",
      "stages.2.blocks.25\n",
      "stages.2.blocks.26\n",
      "stages.3\n",
      "stages.3.blocks.0\n",
      "stages.3.blocks.1\n",
      "stages.3.blocks.2\n",
      "head\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Layer object for key 'stem' is None. Check your layer_mapping.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 106\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# Create an input tensor and extract activations using the custom electrode.\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m    104\u001b[39m input_tensor = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mCustomNeuroElectrodeArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvnext_large\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_mapping\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melectrode\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43melectrode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Print out activation shapes.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/neuroai_kit/electrode.py:59\u001b[39m, in \u001b[36mNeuroElectrodeArray.__enter__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args): \n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhook_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mCustomNeuroElectrodeArray.hook_layers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_id, layer_obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layer_mapping.items():\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m layer_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLayer object for key \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is None. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33mCheck your layer_mapping.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m.hooks[layer_id] = layer_obj.register_forward_hook(\u001b[38;5;28mself\u001b[39m.save_outputs_hook(layer_id))\n",
      "\u001b[31mAttributeError\u001b[39m: Layer object for key 'stem' is None. Check your layer_mapping."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from neuroai_kit.electrode import NeuroElectrodeArray\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Option 2: Custom NeuroElectrodeArray that uses a manual mapping\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "class CustomNeuroElectrodeArray(NeuroElectrodeArray):\n",
    "    \"\"\"\n",
    "    A subclass that overrides hook_layers() to use a manual mapping of\n",
    "    layer names to actual layer objects.\n",
    "    \n",
    "    Parameters:\n",
    "      model: The wrapped model.\n",
    "      layer_mapping: A dict mapping layer names (str) to layer objects (nn.Module).\n",
    "      Other keyword arguments are passed to the parent class.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, layer_mapping, **kwargs):\n",
    "        # Override layers with the keys of our manual mapping.\n",
    "        super().__init__(model, layers=list(layer_mapping.keys()), **kwargs)\n",
    "        self.layer_mapping = layer_mapping\n",
    "\n",
    "    def hook_layers(self):\n",
    "        self.remove_hooks()\n",
    "        # Instead of using model.named_modules(), iterate over our manual mapping.\n",
    "        for layer_id, layer_obj in self.layer_mapping.items():\n",
    "            if layer_obj is None:\n",
    "                raise AttributeError(f\"Layer object for key '{layer_id}' is None. \"\n",
    "                                     \"Check your layer_mapping.\")\n",
    "            self.hooks[layer_id] = layer_obj.register_forward_hook(self.save_outputs_hook(layer_id))\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Manual layer mapping (replace this with your actual code to obtain layers)\n",
    "# -----------------------------------------------------------------------------\n",
    "#\n",
    "# In this example we assume you have some way to retrieve each layer.\n",
    "# For demonstration, we assume your convnext_large object has a custom attribute\n",
    "# (for example, convnext_large.custom_layers) that maps string names to layer objects.\n",
    "#\n",
    "# If your model does not provide this, you need to obtain the layer objects manually.\n",
    "#\n",
    "# For example, if you know the architecture, you might do something like this:\n",
    "#\n",
    "#    layer_mapping = {\n",
    "#         'stem': convnext_large.custom_layers['stem'],\n",
    "#         'stages.0': convnext_large.custom_layers['stages.0'],\n",
    "#         'stages.0.blocks.0': convnext_large.custom_layers['stages.0.blocks.0'],\n",
    "#         ...\n",
    "#         'head': convnext_large.custom_layers['head']\n",
    "#    }\n",
    "#\n",
    "# The following code is pseudocode; adjust the layer counts and retrieval as needed.\n",
    "\n",
    "layer_mapping = {}\n",
    "\n",
    "# Example: assume convnext_large has an attribute 'custom_layers' (this is hypothetical)\n",
    "if hasattr(convnext_large, 'custom_layers'):\n",
    "    # Stem layer\n",
    "    layer_mapping['stem'] = convnext_large.custom_layers.get('stem', None)\n",
    "    \n",
    "    # Suppose there are 4 stages: stage 0, 1, 2, and 3.\n",
    "    for stage_idx in range(4):\n",
    "        stage_name = f'stages.{stage_idx}'\n",
    "        layer_mapping[stage_name] = convnext_large.custom_layers.get(stage_name, None)\n",
    "        # Example: Stage 2 has 27 blocks, others have 3 blocks (adjust as needed)\n",
    "        num_blocks = 27 if stage_idx == 2 else 3\n",
    "        for block_idx in range(num_blocks):\n",
    "            block_name = f'{stage_name}.blocks.{block_idx}'\n",
    "            layer_mapping[block_name] = convnext_large.custom_layers.get(block_name, None)\n",
    "    \n",
    "    # Head layer\n",
    "    layer_mapping['head'] = convnext_large.custom_layers.get('head', None)\n",
    "else:\n",
    "    # If your model does not have 'custom_layers', you must create the mapping manually.\n",
    "    # For example, if you somehow know how to retrieve the layers:\n",
    "    #\n",
    "    #    layer_mapping['stem'] = <your code to get stem layer>\n",
    "    #    layer_mapping['stages.0'] = <your code to get stage 0>\n",
    "    #    layer_mapping['stages.0.blocks.0'] = <your code to get block 0 of stage 0>\n",
    "    #    ...\n",
    "    #\n",
    "    # Here we set them to None to indicate you must fill these in.\n",
    "    layer_mapping['stem'] = None\n",
    "    for stage_idx in range(4):\n",
    "        stage_name = f'stages.{stage_idx}'\n",
    "        layer_mapping[stage_name] = None\n",
    "        num_blocks = 27 if stage_idx == 2 else 3\n",
    "        for block_idx in range(num_blocks):\n",
    "            block_name = f'{stage_name}.blocks.{block_idx}'\n",
    "            layer_mapping[block_name] = None\n",
    "    layer_mapping['head'] = None\n",
    "\n",
    "# (Optional) Print out the layer mapping keys to verify:\n",
    "print(\"Defined layer mapping keys:\")\n",
    "for key in layer_mapping.keys():\n",
    "    print(key)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Create an input tensor and extract activations using the custom electrode.\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "with CustomNeuroElectrodeArray(convnext_large, layer_mapping=layer_mapping) as electrode:\n",
    "    activations = electrode(input_tensor)\n",
    "\n",
    "# Print out activation shapes.\n",
    "print(\"Activation shapes:\")\n",
    "for layer_name, activation in activations.items():\n",
    "    print(f\"{layer_name}: {activation.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available layers from convnext_large.layers:\n",
      "stages.2.blocks.4.conv_dw\n",
      "stages.2.blocks.3\n",
      "stages.2.blocks.4.conv_dw\n",
      "stages.2.downsample.1\n",
      "head.pre_logits\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ModelCommitment' object has no attribute 'register_hook'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Register hooks for each available layer using the wrapper's register_hook method.\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_name \u001b[38;5;129;01min\u001b[39;00m convnext_large.layers:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[43mconvnext_large\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister_hook\u001b[49m(layer_name, hook_fn(layer_name))\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Run a forward pass through the model.\u001b[39;00m\n\u001b[32m     26\u001b[39m _ = convnext_large(input_tensor)\n",
      "\u001b[31mAttributeError\u001b[39m: 'ModelCommitment' object has no attribute 'register_hook'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create an input tensor (adjust shape as needed)\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# This dictionary will collect activations by layer name.\n",
    "activations = {}\n",
    "\n",
    "# Define a hook function that stores the output in the activations dict.\n",
    "def hook_fn(name):\n",
    "    def hook(module, inp, out):\n",
    "        activations[name] = out\n",
    "        print(f\"Hook for {name}: output shape {out.shape}\")\n",
    "    return hook\n",
    "\n",
    "# Print out the available layer names (these are provided by the wrapper)\n",
    "print(\"Available layers from convnext_large.layers:\")\n",
    "for layer_name in convnext_large.layers:\n",
    "    print(layer_name)\n",
    "\n",
    "# Register hooks for each available layer using the wrapper's register_hook method.\n",
    "for layer_name in convnext_large.layers:\n",
    "    convnext_large.register_hook(layer_name, hook_fn(layer_name))\n",
    "\n",
    "# Run a forward pass through the model.\n",
    "_ = convnext_large(input_tensor)\n",
    "\n",
    "# Print out the collected activation shapes.\n",
    "print(\"\\nCollected activations:\")\n",
    "for name, act in activations.items():\n",
    "    print(f\"{name}: {act.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the underlying model!\n"
     ]
    }
   ],
   "source": [
    "underlying_model = getattr(convnext_large, '_model', None)\n",
    "if underlying_model is None:\n",
    "    underlying_model = getattr(convnext_large, 'model', None)\n",
    "if underlying_model is not None:\n",
    "    for name, module in underlying_model.named_modules():\n",
    "        print(name, module.__class__.__name__)\n",
    "else:\n",
    "    print(\"Could not find the underlying model!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelCommitment' object has no attribute 'named_modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNeuroElectrodeArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvnext_large\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melectrode\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43melectrode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/neuroai_kit/electrode.py:59\u001b[39m, in \u001b[36mNeuroElectrodeArray.__enter__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args): \n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhook_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/neuroai_kit/electrode.py:47\u001b[39m, in \u001b[36mNeuroElectrodeArray.hook_layers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mself\u001b[39m.remove_hooks()\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     layer = \u001b[38;5;28mdict\u001b[39m([*\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnamed_modules\u001b[49m()])[layer_id]\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mself\u001b[39m.hooks[layer_id] = layer.register_forward_hook(\u001b[38;5;28mself\u001b[39m.save_outputs_hook(layer_id))\n",
      "\u001b[31mAttributeError\u001b[39m: 'ModelCommitment' object has no attribute 'named_modules'"
     ]
    }
   ],
   "source": [
    "\n",
    "with NeuroElectrodeArray(convnext_large, layers = layers) as electrode:\n",
    "    activations = electrode(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelCommitment' object has no attribute 'stages'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mneuroai_kit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01melectrode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeuroElectrodeArray\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Define your layers dictionary as you intended:\u001b[39;00m\n\u001b[32m      6\u001b[39m layers = {\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mstem\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mstages\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mconvnext_large\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstages\u001b[49m))),\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mblocks\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m     10\u001b[39m         stage_idx: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(stage.blocks)))\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m stage_idx, stage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(convnext_large.stages)\n\u001b[32m     12\u001b[39m     },\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhead\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     14\u001b[39m }\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Using NeuroElectrodeArray directly:\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m NeuroElectrodeArray(convnext_large, layers=layers) \u001b[38;5;28;01mas\u001b[39;00m electrode:\n",
      "\u001b[31mAttributeError\u001b[39m: 'ModelCommitment' object has no attribute 'stages'"
     ]
    }
   ],
   "source": [
    "import neuroai_kit as nk\n",
    "from neuroai_kit import model_utils\n",
    "from neuroai_kit.electrode import NeuroElectrodeArray\n",
    "\n",
    "# Define your layers dictionary as you intended:\n",
    "layers = {\n",
    "    'stem': True,\n",
    "    'stages': list(range(len(convnext_large.stages))),\n",
    "    'blocks': {\n",
    "        stage_idx: list(range(len(stage.blocks)))\n",
    "        for stage_idx, stage in enumerate(convnext_large.stages)\n",
    "    },\n",
    "    'head': True\n",
    "}\n",
    "\n",
    "# Using NeuroElectrodeArray directly:\n",
    "with NeuroElectrodeArray(convnext_large, layers=layers) as electrode:\n",
    "    activations = electrode(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PytorchWrapper' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconvnext_large\u001b[49m\u001b[43m.\u001b[49m\u001b[43mactivations_model\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'PytorchWrapper' object is not iterable"
     ]
    }
   ],
   "source": [
    "for name, module in convnext_large.activations_model:\n",
    "    print(name, module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context on how I previously accessed all activations\n",
    "import neuroai_kit as nk\n",
    "from neuroai_kit import model_utils\n",
    "\n",
    "model = load_model(width = 'w1', task = 'supervised')\n",
    "layer_names = model_utils.get_layers(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# Load dataset\n",
    "dataset_path = \"s3://visionlab-litdata/exploring-objects-images/\"\n",
    "\n",
    "# moves imgs to GPU before running loops to extract activations\n",
    "img_batch = load_data(dataset_path).to(device) # this moves images to GPU early\n",
    "model.eval()\n",
    "with torch.no_grad():    \n",
    "    with nk.NeuroElectrodeArray(model, layer_names) as electrode:\n",
    "        activations = electrode(img_batch)\n",
    "for layer_name, act in activations.items():\n",
    "    print(layer_name, act.shape)\n",
    "# saving extraction activations for all layers using nk\n",
    "all_activations = {}\n",
    "for layer_name, act in activations.items():\n",
    "    act_np = act.cpu().numpy() if act.is_cuda else act.numpy()\n",
    "    if act_np.ndim > 2:\n",
    "        act_np = act_np.reshape(act_np.shape[0], -1)\n",
    "    all_activations[layer_name] = act_np\n",
    "\n",
    "# Save all activations to a single npz file\n",
    "output_file = os.path.join('activations', \"all_layer_activations.npz\")\n",
    "np.savez_compressed(output_file, **all_activations)\n",
    "print(f\"Saved all activations in {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract all activations from all layers\n",
    "def convnext_large_activations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelCommitment' object has no attribute 'stages'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mconvnext_large\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstages\u001b[49m[\u001b[32m0\u001b[39m].blocks):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBlock \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblock\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'ModelCommitment' object has no attribute 'stages'"
     ]
    }
   ],
   "source": [
    "for i, block in enumerate(convnext_large.stages[0].blocks):\n",
    "    print(f\"Block {i}: {block}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# raw model with no wrapper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'neuroai_kit.model_utils' has no attribute 'load_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mneuroai_kit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model_utils\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Try to load the raw model (if the library supports a flag or a different function)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m raw_model = \u001b[43mmodel_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mconvnext_large_mlp:clip_laion2b_augreg_ft_in1k_384\u001b[39m\u001b[33m'\u001b[39m, raw=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'neuroai_kit.model_utils' has no attribute 'load_model'"
     ]
    }
   ],
   "source": [
    "from neuroai_kit import model_utils\n",
    "\n",
    "# Try to load the raw model (if the library supports a flag or a different function)\n",
    "raw_model = model_utils.load_model('convnext_large_mlp:clip_laion2b_augreg_ft_in1k_384', raw=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXt(\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (1): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (stages): Sequential(\n",
      "    (0): ConvNeXtStage(\n",
      "      (downsample): Identity()\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ConvNeXtStage(\n",
      "      (downsample): Sequential(\n",
      "        (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): ConvNeXtStage(\n",
      "      (downsample): Sequential(\n",
      "        (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (4): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (5): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (6): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (7): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (8): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (9): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (10): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (11): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (12): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (13): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (14): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (15): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (16): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (17): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (18): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (19): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (20): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (21): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (22): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (23): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (24): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (25): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (26): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): ConvNeXtStage(\n",
      "      (downsample): Sequential(\n",
      "        (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(768, 1536, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
      "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
      "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
      "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm_pre): Identity()\n",
      "  (head): NormMlpClassifierHead(\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "    (norm): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (pre_logits): Sequential(\n",
      "      (fc): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (act): GELU()\n",
      "    )\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(convnext_large.activations_model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PytorchWrapper' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m raw_model = convnext_large.activations_model  \u001b[38;5;66;03m# This is the raw ConvNeXt model.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[43mraw_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m.named_modules():\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(name, module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'PytorchWrapper' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "raw_model = convnext_large.activations_model  # This is the raw ConvNeXt model.\n",
    "for name, module in raw_model.named_modules():\n",
    "    print(name, module.__class__.__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelCommitment' object has no attribute 'get_activations'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m activations = \u001b[43mconvnext_large\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_activations\u001b[49m(input_tensor)\n",
      "\u001b[31mAttributeError\u001b[39m: 'ModelCommitment' object has no attribute 'get_activations'"
     ]
    }
   ],
   "source": [
    "activations = convnext_large.get_activations(input_tensor)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
